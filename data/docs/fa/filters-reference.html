<!DOCTYPE html>
<html>
  <head>
    <link href="../style/style.css" rel="stylesheet" type="text/css" />
    <meta charset="utf-8" />
  </head>
  <body>
    <h1><a name="Filters-Reference">Filters Reference</a></h1>
    <hr />
    <h2><a name="Load">Load</a></h2>
    <p><em>Loads image and video files.</em></p>
    <hr />
    <h3><a name="Image-Loader">Image Loader</a></h3>
    <p><em>Loads an image from file.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Image Loader</em> tool renders an image file that can be encoded
      in a variety of formats to a bitmap that can be displayed and processed.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>File</strong><br />
        <em>The path of the file to load.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>Load a snapshot from a CCTV video.<a href="" target="_blank"></a></li>
      <li>
        Load an image from a mobile phone or digital camera.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>Load an image from the web.<a href="" target="_blank"></a></li>
      <li>Load an image in RAW format.<a href="" target="_blank"></a></li>
    </ul>
    <hr />
    <h3><a name="Sequence-Loader">Sequence Loader</a></h3>
    <p><em>Loads multiple images as video.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Sequence Loader</em> tool renders different image files that can
      be encoded in a variety of formats to a sequence of bitmaps that can be
      displayed and processed.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Files</strong><br />
        <em>Path of the images in the list.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Fps</strong><br />
        <em>Frame rate, in frames per second, for the resulting video.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      All common image formats are supported, but all images must have the same
      size. If the images have different size, the reference size will be taken
      from the first one. Other images will be cropped to fit in the reference
      size. This is quite normal if images are taken by the same source. The
      default sorting is alphabetical, but you can adjust it by selecting items
      in the list and using buttons on the right side of the list box.<br />
      For configuring filter, you can drag and drop multiple files or entire
      folders over this window or directly on the main window.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Load multiple images in sequence and process them together.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Load frames extracted from a proprietary DVR player.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Video-Loader">Video Loader</a></h3>
    <p><em>Loads a video from file.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Video Loader</em> tool renders a video file that can be encoded in
      a variety of standard formats to a sequence of bitmaps that can be
      displayed and processed.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>File</strong><br />
        <em>Path of the video to load.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Video Engine</strong><br />
        <em>Video decoder to use.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Color Range</strong><br />
        <em
          >Use the color range specified in the video file or force it to full
          or limited (16-235). Works only with the FFMS Video Engine.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Original File</strong><br />
        <em
          >Original video file that has been converted from a proprietary DVR
          format.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Milestone-Client">Milestone Client</a></h3>
    <p>
      <em
        >Connects to a Milestone XProtect image server to get archived or live
        images.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Milestone Client</em> tool allows loading images stored on a
      Milestone XProtect images server without the need to export them to
      another format. For further information refer to the website
      www.milestonesys.com and the documentation provided with the Milestone
      XProtect video management system.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Server Address</strong><br />
        <em>IP address or server name of the host Milestone XProtect Server.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Authentication</strong><br />
        <em>The authentication type used.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Username</strong><br />
        <em>User name to connect to the server.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Password</strong><br />
        <em>Password to connect to the server.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Auto Login</strong><br />
        <em>Connects automatically every time Milestone Client is loaded.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Camera</strong><br />
        <em>Camera to connect to.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Live Video</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Process videos captured directly from the city CCTV network.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Enhance live videos during surveillance operations.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Milestone-Archive">Milestone Archive</a></h3>
    <p>
      <em
        >Loads a video exported from a Milestone XProtect server without need
        for conversion.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Milestone Archive</em> loads a video format in the native format
      created by Milestone XProtect.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>File</strong><br />
        <em>Path of the video to load.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Media (XML archives)</strong><br />
        <em>Media name; makes sense only in XML archives</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Image-Paster">Image Paster</a></h3>
    <p><em>Pastes the image from the clipboard for further processing.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Image Paster</em> tool encodes the image currently in the
      clipboard to the specified file with the chosen format.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>File</strong><br />
        <em>Path of the image to save.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Format</strong><br />
        <em>Format used to encode the image file.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Quality</strong><br />
        <em
          >Quality of the image to save (JPEG only, the bigger is the
          better).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Process an image copied to the clipboard from the web or another
        program.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Video-Input">Video Input</a></h3>
    <p>
      <em
        >Live stream DirectShow video sources for real time display or
        capture.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Video Input</em> allows to view real time full motion video coming
      from any DirectShow compatible device.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Device</strong><br />
        <em>Name of video input device.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>File</strong><br />
        <em>Path of the file to save.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Format</strong><br />
        <em>Container and codec used to write the video file.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Frame rate</strong><br />
        <em
          >Frame rate (in frames per second) of the output video. Note that some
          video formats support only a limited set of frame rates.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Quality</strong><br />
        <em
          >If a codec has been selected that allows quality control, the
          following options can be selected:<br />
          <em>Default</em>: Uses a Constant Rate Factor of 18<br />
          <em>High</em>: Uses a Constant Rate Factor of 12<br />
          <em>Visually Lossless</em>: Uses a Constant Rate Factor of 1<br /> </em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Working with a live video input is the same as with an image or archived
      video files, but some filters, such as those in the group
      <em>Select Frames</em>, cannot be applied to a live feed.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Process live videos coming from a webcam.<a href="" target="_blank"></a>
      </li>
      <li>
        Capture analog video coming from a frame grabber.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        Video Input :
        <a
          href="https://blog.ampedsoftware.com/2016/08/24/video-input/"
          target="_blank"
          >https://blog.ampedsoftware.com/2016/08/24/video-input/</a
        >
      </li>
    </ul>
    <hr />
    <h2><a name="Link">Link</a></h2>
    <p><em>Connects and mixes different source filters.</em></p>
    <hr />
    <h3><a name="Video-Mixer">Video Mixer</a></h3>
    <p>
      <em
        >Overlays or displays two different chains side by side. Supports
        synchronization of streams and similarity metrics computation.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Video Mixer</em> filter allows to mix the images from other two
      chains, or to put them side by side. It also computes and shows the
      similarity between corresponding frames of the two videos using multiple
      metrics.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>First Input</strong><br />
        <em>First filter to mix.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Second Input</strong><br />
        <em>Second filter to mix.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Video to Seek</strong><br />
        <em>Select which video to seek, or both.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selected Frames</strong><br />
        <em>Two specific positions in the mixed videos to compare.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em
          >How to display the processed and the original (or unprocessed)
          images, videos or frames.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Size</strong><br />
        <em>The size of the output image.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Mode</strong><br />
        <em
          >What to do if the output image has a different size than the
          input.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Interpolation</strong><br />
        <em>Interpolation algorithm.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Balance</strong><br />
        <em>Balance between the original (0) and processed image (1).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Gain</strong><br />
        <em>Gain applied to the output image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Line Color</strong><br />
        <em
          >The color of the separating line in Half Horizontally and Half
          Vertically mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Line Thickness</strong><br />
        <em
          >The thickness of the separating line in Half Horizontally and Half
          Vertically mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Compute Similarity Metrics</strong><br />
        <em>Enable/disable the computation of similarity metrics.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Similarity Metrics</strong><br />
        <em>The similarity metrics are shown below if available.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>SAD (0 .. 255)</strong><br />
        <em>Sum of Absolute Differences (mean).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>PSNR (dB)</strong><br />
        <em>Peak Signal to Noise Ratio.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>MSSIM (0 .. 1)</strong><br />
        <em>Mean Structural Similarity.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Correlation (-1 .. 1)</strong><br />
        <em>Correlation Coefficient.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Audio Source</strong><br />
        <em>Select the audio (if available) played in the output video.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The <em>Video Mixer</em> filter must always be positioned in the history
      under the filters it links, otherwise the project cannot load
      successfully. Also, don't delete the filters the <em>Video Mixer</em> is
      linking to, or it will not have proper sources anymore.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>Put two videos side by side.<a href="" target="_blank"></a></li>
      <li>
        Overlay two images to analyze the differences.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Perform reverse projection to compare a suspect to an unknown subject in
        a CCTV video.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Z. Wang, A. C. Bovik, H. R. Sheikh and E. P. Simoncelli, “Image quality
        assessment: From error visibility to structural similarity”, in IEEE
        Transactions on Image Processing, Vol. 13, No. 4, pp. 600–612, Apr.
        2004.
        <a href="http://dx.doi.org/10.1109/TIP.2003.819861" target="_blank"
          >http://dx.doi.org/10.1109/TIP.2003.819861</a
        >
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        بـستا Update: The Video Mixer Filter:
        <a
          href="https://blog.ampedsoftware.com/2015/08/10/amped-five-update-the-video-mixer-filter/"
          target="_blank"
          >https://blog.ampedsoftware.com/2015/08/10/amped-five-update-the-video-mixer-filter/</a
        >
      </li>
      <li>
        What’s the Difference?:
        <a
          href="https://blog.ampedsoftware.com/2018/04/09/whats-the-difference/"
          target="_blank"
          >https://blog.ampedsoftware.com/2018/04/09/whats-the-difference/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Perspective-Aligner">Perspective Aligner</a></h3>
    <p>
      <em
        >Display two chains, either side by side or overlaid, and optionally
        warp one of them in order to simulate an identical point of view.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Perspective Aligner</em> tool allows for the display of two chains
      simultaneously, either side by side or overlaid with adjustable weight. It
      is optionally possible to apply a perspective warp to one of the two
      images by selecting four corresponding points. This simulates the effect
      of moving the point of view of that image to match that of the other one.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>First input</strong><br />
        <em>First filter to mix.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Second input</strong><br />
        <em>Second filter to mix.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em>How to mix the two sources.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Balance</strong><br />
        <em>Weight of the two sources (-1 = first, 1 = second).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Gain</strong><br />
        <em>Gain applied to the output image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Line Color</strong><br />
        <em
          >The color of the separating line in Half Horizontally and Half
          Vertically mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Line Thickness</strong><br />
        <em
          >The thickness of the separating line in Half Horizontally and Half
          Vertically mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Perspective</strong><br />
        <em>Which perspective to change.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Matching Points</strong><br />
        <em>Pairs of points mapping from the first image to the second one.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Audio Source</strong><br />
        <em>Select the audio (if available) played in the output video.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Use the <em>Ruler</em> tool, in the <em>Perspective</em> tab, to draw at
      least 4 lines that connect a point in the first image to the corresponding
      point in the second image.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Align two images with different perspectives to analyze the
        differences.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        Different Points of View? No Problem! Use بـستا’s Perspective Aligner to
        Compare or Integrate Images Taken From Different Angles!:
        <a
          href="https://blog.ampedsoftware.com/2020/02/04/different-points-of-view-no-problem-use-amped-fives-perspective-aligner-to-compare-or-integrate-images-taken-from-different-angles/"
          target="_blank"
          >https://blog.ampedsoftware.com/2020/02/04/different-points-of-view-no-problem-use-amped-fives-perspective-aligner-to-compare-or-integrate-images-taken-from-different-angles/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Timeline">Timeline</a></h3>
    <p><em>Displays multiple videos one after the other.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Timeline</em> filter displays multiple videos one after the other.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Input To Add</strong><br />
        <em>The filter to add to the list below.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Inputs</strong><br />
        <em>The list of filters to display one after the other</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Size</strong><br />
        <em>The size of each cell in the output grid.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Mode</strong><br />
        <em>What to do if the cell has a different size than the input.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Interpolation</strong><br />
        <em>Interpolation algorithm.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The <em>Timeline</em> filter must always be positioned in the history
      under the filters it links, otherwise the project cannot load
      successfully. Also, don't delete the filters the <em>Timeline</em> is
      linking to, or it will not have proper sources anymore.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Play multiple videos one after the other.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Multiview">Multiview</a></h3>
    <p>
      <em
        >Displays multiple chains simultaneously on a grid. Supports
        synchronization of streams.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Multiview</em> filter displays multiple chains simultaneously on a
      grid.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Rows</strong><br />
        <em>The number of rows in the layout.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Columns</strong><br />
        <em>The number of columns in the layout.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Input To Add</strong><br />
        <em>The filter to add to the list below.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Inputs</strong><br />
        <em>The list of filters to display in a grid</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Input Delay</strong><br />
        <em>Two specific positions in the mixed videos to compare.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Size</strong><br />
        <em>The size of each cell in the output grid.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Mode</strong><br />
        <em>What to do if the cell has a different size than the input.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Interpolation</strong><br />
        <em>Interpolation algorithm.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Line Color</strong><br />
        <em>The color of the optional line separating the cells.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Line Thickness</strong><br />
        <em>The thickness of the optional line separating the cells.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Audio Source</strong><br />
        <em>The input (if available) whose audio is played.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The <em>Multiview</em> filter must always be positioned in the history
      under the filters it links, otherwise the project cannot load
      successfully. Also, don't delete the filters the <em>Multiview</em> is
      linking to, or it will not have proper sources anymore.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        View multiple videos simultaneously on a grid.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        The Bigger Picture: Did You Know بـستا’s Multiview Filter Lets You
        Combine and Sync Multiple Videos?:
        <a
          href="https://blog.ampedsoftware.com/2019/10/22/the-bigger-picture-did-you-know-amped-fives-multiview-filter-lets-you-combine-and-sync-multiple-videos/"
          target="_blank"
          >https://blog.ampedsoftware.com/2019/10/22/the-bigger-picture-did-you-know-amped-fives-multiview-filter-lets-you-combine-and-sync-multiple-videos/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Picture-In-Picture">Picture In Picture</a></h3>
    <p><em>Displays a smaller image or video on top of a larger one.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Picture In Picture</em> filter displays a smaller image or video
      on top of a larger one. The size of the output is equal to the size of the
      background image. The size and position of the foreground image can be set
      using the <em>Selection</em> tab.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Background Input</strong><br />
        <em
          >Image or video to display on the background (determines the size of
          the output frame).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Foreground Input</strong><br />
        <em>Image or video to display on the foreground.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Optionally resize the foreground image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Interpolation</strong><br />
        <em>Interpolation algorithm.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Horizontal Position</strong><br />
        <em
          >Horizontal position of the foreground image with respect to the frame
          or selection.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Vertical Position</strong><br />
        <em
          >Vertical position of the foreground image with respect to the frame
          or selection.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Transparency</strong><br />
        <em>Optional transparency of the inner filter.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Border Color</strong><br />
        <em>The color of the optional border</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Border Thickness</strong><br />
        <em>The thickness of the border (set to 0 to disable the border).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Audio Source</strong><br />
        <em>Select the audio (if available) played in the output video.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The <em>Picture In Picture</em> filter must always be positioned in the
      history under the filters it links, otherwise the project cannot load
      successfully. Also, don't delete the filters the
      <em>Picture In Picture</em> is linking to, or it will not have proper
      sources anymore.
    </p>
    <hr />
    <h2><a name="Write">Write</a></h2>
    <p>
      <em
        >Writes image and video files after processing filters have been
        applied.</em
      >
    </p>
    <hr />
    <h3><a name="Image-Writer">Image Writer</a></h3>
    <p><em>Writes the current image to a new file.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Image Writer</em> tool encodes the current frame to the specified
      file with the chosen format.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>File</strong><br />
        <em>Path of the image to save.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Format</strong><br />
        <em>Format used to encode the image file.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Quality</strong><br />
        <em
          >Quality of the image to save (the higher it is, the better it is).
          Used only when saving in Jpeg format.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Frame Position</strong><br />
        <em>Position of the saved frame in the input video.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Align two images with different perspectives to analyze the
        differences.<a href="" target="_blank"></a>
      </li>
      <li>
        Process an image and save the results.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Sequence-Writer">Sequence Writer</a></h3>
    <p><em>Writes all frames as image files.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Sequence Writer</em> tool encodes all the frames of the current
      video to a sequence of the specified files with the chosen format.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Output Folder</strong><br />
        <em>Destination folder where to save the images.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Format</strong><br />
        <em>Format used to encode the image file.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Quality</strong><br />
        <em>Quality of the images.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>First Frame Number</strong><br />
        <em>Identificative number of the first frame.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Files</strong><br />
        <em>Output files paths.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Save the result of the processing as separate frames.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Convert a video to a sequence of images.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Video-Writer">Video Writer</a></h3>
    <p><em>Writes the current video to a file.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Video Writer</em> tool encodes all frames of the current video to
      the specified video file format.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>File</strong><br />
        <em>Path of the file to save.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Format</strong><br />
        <em>Container and codec used to write the video file.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Frame rate</strong><br />
        <em
          >Frame rate (in frames per second) of the output video. Note that some
          video formats support only a limited set of frame rates.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Quality</strong><br />
        <em
          >If a codec has been selected that allows quality control, the
          following options can be selected:<br />
          <em>Default</em>: Uses a Constant Rate Factor of 18<br />
          <em>High</em>: Uses a Constant Rate Factor of 12<br />
          <em>Visually Lossless</em>: Uses a Constant Rate Factor of 1<br /> </em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      For uncompressed video use <em>avi - Raw video</em>. The resulting file
      size could be very large.<br />
      For high quality with low compression video use <em>mp4 – H264</em> with a
      visually lossless quality setting.<br />
      For compatibility with other players use, <em>avi – MSMPEG4v3</em><br />
      <br />
      Padding will be automatically applied if the video Width and Height are
      not divisible by 4 to ensure encoding standards are met. Be aware of this
      issue if comparing the new video with the original.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Save the result of the processing as a video file.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Convert a sequence of images to a video.<a href="" target="_blank"></a>
      </li>
      <li>
        Convert a video to an easily playable format.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Save the intermediate results of processing without losing quality
        (uncompressed).<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h2><a name="Select-Frames">Select Frames</a></h2>
    <p><em>Selects video frames.</em></p>
    <hr />
    <h3><a name="Single-Selector">Single Selector</a></h3>
    <p><em>Selects a single frame of the video.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Single Selector</em> tool gives in output only the selected frame
      of the current video.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Frame</strong><br />
        <em>Frame number to be selected.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Select the only frame where a detail is visible.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Range-Selector">Range Selector</a></h3>
    <p>
      <em
        >Selects frames of the video within an interval with an optional step.
        Support the trimming of the original video stream without
        transcoding.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Range Selector</em> tool outputs a video of specific frames that
      are part of the input video.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>First Frame</strong><br />
        <em>First frame of the selection of interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Last Frame</strong><br />
        <em>Last frame of the selection of interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Step</strong><br />
        <em>Take only one frame every <em>Step</em> frames.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Select the frames where a car of interest is passing.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Select the good interval of frames before integrating them.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>Trim a video without reencoding.<a href="" target="_blank"></a></li>
    </ul>
    <hr />
    <h3><a name="Sparse-Selector">Sparse Selector</a></h3>
    <p><em>Selects a list of frames that are defined by the user.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Sparse Selector</em> tool outputs multiple frames taken from user
      selected positions of an input video.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Frames</strong><br />
        <em>List of selected frames.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Select a few interesting frames in a video.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Select the best frames before integrating them.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Discard badly stabilized frames after a stabilization.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Manually demultiplex a video with various cameras.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        The Sparse Selector:
        <a
          href="https://blog.ampedsoftware.com/2017/11/27/the-sparse-selector/"
          target="_blank"
          >https://blog.ampedsoftware.com/2017/11/27/the-sparse-selector/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Remove-Duplicates">Remove Duplicates</a></h3>
    <p>
      <em
        >Removes duplicate frames with the ability to set a similarity
        threshold.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Remove Duplicates</em> tool removes all frames that are just a
      copy of the previous one(s).
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Difference</strong><br />
        <em
          >Average difference between pixels of the current and the previous
          frame.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Threshold</strong><br />
        <em
          >Maximum difference between two frames to consider them duplicates.
          Usually set to 0 for digital videos and to a bigger value for videos
          digitized from an analog source.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Adjust Frame Rate</strong><br />
        <em>Frame rate adjustment settings.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Frame Rate</strong><br />
        <em>Frame rate of the output video.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Frames</strong><br />
        <em>List of different frames (output parameter).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Remove duplicated frames due to encoding issues.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Remove duplicated frames from a video captured at the wrong frame rate
        (screen capture or frame grabber) or with variable frame rate.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="IFrames-Selector">IFrames Selector</a></h3>
    <p><em>Selects IntraFrames of a video.</em></p>
    <h4>Details</h4>
    <p>
      The <em>IFrames Selector</em> tool selects only full frames (I-frames) of
      a video. I-frames are usually more accurate and of better quality than
      other frames of a video. This filter works only with
      <em>Video Loader</em> with <em>Video Engine</em> set to <em>FFMS</em>.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Frames</strong><br />
        <em>List of I-frames (output parameter).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>Solve seeking and encoding issues.<a href="" target="_blank"></a></li>
      <li>
        Select only the frames with best quality (beware that sometimes there is
        good info also in P/B frames, but it can be useful where we have
        hundreds or thousands of frames to integrate).<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Remove-Frames">Remove Frames</a></h3>
    <p><em>Removes individual frames defined by the user.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Remove Frames</em> tool removes from the input video a list of
      frames selected by the user in arbitrary positions.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Frames</strong><br />
        <em>List of frames to remove.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Select a few interesting frames in a video.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Select the best frames before integrating them.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Discard badly stabilized frames after a stabilization.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Manually demultiplex a video with various cameras.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Auto-Selector">Auto Selector</a></h3>
    <p>
      <em
        >Automatically selects similar frames (to discard bad frames) with the
        ability to set a similarity threshold and a reference frame.</em
      >
    </p>
    <h4>Details</h4>
    <p></p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Reference Frame</strong><br />
        <em>Frame to keep as reference for the correlation.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em>Region where to check the correlation.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Correlation</strong><br />
        <em>Correlation between current images selection and template.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Threshold</strong><br />
        <em>Minimum correlation for valid frames.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Frames</strong><br />
        <em
          >List of valid frames, whose correlation is bigger than threshold
          (output parameter).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Discard badly stabilized frames after a stabilization.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Demultiplex difficult multiplexed videos selecting a specific area of
        interest to look for.<a href="" target="_blank"></a>
      </li>
      <li>
        Select only similar frames, useful in some specific kind of
        multiplexing.<a href="" target="_blank"></a>
      </li>
      <li>
        Intracamera demultiplexing for sweeping PTZ cameras.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Demultiplexer">Demultiplexer</a></h3>
    <p>
      <em
        >Separates different scenes multiplexed in the same video. Supports the
        automatic export of multiple channels with a single action.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Demultiplexer</em> tool takes as input a multiplexed video and
      gives in output the frames grouped by source camera, thus allowing the
      user to work more comfortably. Multiplexed videos are usually coming from
      analog systems, where the signal from different cameras was saved in the
      same video alternating the scene in every frame.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Threshold</strong><br />
        <em
          >Smallest possible match value for associating a frame with a
          scene.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Scenes</strong><br />
        <em>Frames grouped by scene (output parameter).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Scene</strong><br />
        <em>Selected scene for display.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Frames</strong><br />
        <em>List of frames for the selected scene (output parameter).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Write every scene to a separate file</strong><br />
        <em>If selected, saves every scene to an independent video file.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>File</strong><br />
        <em>Path of the file to save.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Format</strong><br />
        <em>Container and codec used to write the video file.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Quality</strong><br />
        <em
          >If a codec has been selected that allows quality control, the
          following options can be selected:<br />
          <em>Default</em>: Uses a Constant Rate Factor of 18<br />
          <em>High</em>: Uses a Constant Rate Factor of 12<br />
          <em>Visually Lossless</em>: Uses a Constant Rate Factor of 1<br /> </em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Demultiplex videos from analog systems.<a href="" target="_blank"></a>
      </li>
      <li>
        Demultiplex videos digitally multiplexed.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Motion-Detection">Motion Detection</a></h3>
    <p>
      <em>Finds events in a video and marks the areas with movement in red.</em>
    </p>
    <h4>Details</h4>
    <p>
      <em>Motion Detection</em> finds events of interest in a video quickly by
      only stopping on the frames where motion is found. It is possible to set
      the detection only within a specific region of the image. In order to make
      the results more robust, a background image is generated for comparison by
      multiple frames and a denoising filter is applied.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Frame Motion</strong><br />
        <em>Estimated amount of motion for the current frame.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Motion Threshold</strong><br />
        <em>The threshold for automatic motion detection.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Frames</strong><br />
        <em>The number of frames to use for background estimation.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Denoising</strong><br />
        <em>The number of iterations for noise removal.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em>The area of the image where motion detection is performed.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Find all the moments when a car is arriving.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Find all the moments where, for example, a person is coming or something
        is happening.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        بـستا’s Motion Detection: the way to skip the noise and focus on the
        action!:
        <a
          href="https://blog.ampedsoftware.com/2019/04/09/amped-fives-motion-detection-the-way-to-skip-the-noise-and-focus-on-the-action/"
          target="_blank"
          >https://blog.ampedsoftware.com/2019/04/09/amped-fives-motion-detection-the-way-to-skip-the-noise-and-focus-on-the-action/</a
        >
      </li>
    </ul>
    <hr />
    <h2><a name="Deinterlacing">Deinterlacing</a></h2>
    <p><em>Processes the interlaced videos.</em></p>
    <hr />
    <h3><a name="Line-Doubling">Line Doubling</a></h3>
    <p><em>Corrects the height of field based video.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Line Doubling</em> filter doubles the height of an image which
      appears vertically squeezed because of an incomplete deinterlacing process
      or other issues in the decoding. Only one line every two will be
      interpolated, while the others will be kept at the original pixel
      values.<br />
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Interpolation</strong><br />
        <em
          >The algorithm used to reconstruct a full size frame from a half
          vertical-resolution one. <em>Replication</em> simply copies the
          adjacent line, <em>Linear</em> interpolates two adjacent lines,
          <em>Cubic</em> interpolates by considering also more distant
          lines.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Correct the aspect ratio to avoid stretched images.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Reconstruct the proper ratio for further processing, measurement and
        analysis. For example, before undistort.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        E. B. Bellers and G. de Haan, “Deinterlacing - An overview”, in
        Proceedings of the IEEE, Vol. 86, No. 9, pp. 1839–1857, Sep. 1998.
        <a href="http://dx.doi.org/10.1109/5.705528" target="_blank"
          >http://dx.doi.org/10.1109/5.705528</a
        >
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        What’s wrong with this video?:
        <a
          href="https://blog.ampedsoftware.com/2017/07/24/whats-wrong-with-this-video/"
          target="_blank"
          >https://blog.ampedsoftware.com/2017/07/24/whats-wrong-with-this-video/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Interleave">Interleave</a></h3>
    <p>
      <em>Converts a video with juxtaposed fields into an interlaced video.</em>
    </p>
    <h4>Details</h4>
    <p>
      <em>Interleave</em> converts a video, in which the two fields are
      juxtaposed one above the other, into an ordinary interlaced video.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Field Order</strong><br />
        <em
          >The order in which the two halves of the input video are
          interleaved.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        In rare situations, some DVR models save two fields in the upper and
        lower half of the picture. This filter converts them to a normal
        interlaced format.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        بـستا Update: The Interleave Filter:
        <a
          href="https://blog.ampedsoftware.com/2015/08/07/amped-five-update-the-interleave-filter/"
          target="_blank"
          >https://blog.ampedsoftware.com/2015/08/07/amped-five-update-the-interleave-filter/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Deinterlace">Deinterlace</a></h3>
    <p>
      <em
        >Converts interlaced videos into progressive ones. Supports several
        options to choose active fields, their order and the interpolation
        method.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Deinterlace</em> tool converts an interlaced video into a
      progressive one.<br />
      In an interlaced video, two subsequent fields are stored in every frame:
      the first in the even lines (even field) and the second in the odd lines
      (odd field), or vice versa. Being the image coordinates zero based, the
      even field is the top one. Even lines are discarded from the odd field
      while odd lines are discarded from the even field.<br />
      The deinterlacing process consists of two steps:<br />
      1) separates even and odd fields from each input frame, creating two
      frames whose height is half of the input height; the output video will
      thus have twice the frames of the input;<br />
      2) interpolates the missing rows with the chosen algorithm; once the
      interpolation is performed, each frame of the output sequence will have
      the same size of the input frames.<br />
      The available interpolation algorithms are:<br />
      - <em>None</em>: no interpolation is done, thus the output image height
      will be half of the input one;<br />
      - <em>Replication</em>: fields are replicated, so each missing line is
      copied from the previous one for odd fields and the next one for even
      fields;<br />
      - <em>Linear</em>: missing lines are created through the closest upper and
      lower lines;<br />
      - <em>Cubic</em>: missing lines are calculated by the four closest
      lines.<br />
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Separate Fields</strong><br />
        <em>Select if fields need to be separated and their order.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Interpolation</strong><br />
        <em
          >The algorithm used to reconstruct a full size frame from a half
          vertical-resolution one. <em>None</em> leaves half resolution,
          <em>Replication</em> simply copies the adjacent line,
          <em>Linear</em> interpolates two adjacent lines,
          <em>Cubic</em> interpolates by considering also more distant lines,
          <em>CRT Simulation</em> leaves the lines from the other field black
          (simulating the appearance of a Cathode Ray Tube).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      In general, you will have to separate the fields; however this operation
      is, in some cases, already done. If this is the case, the source video
      appears "stretched", and you have to choose either
      <em>No - Same Field</em> or <em>No - Alternating Fields</em> as
      <em>Separate Fields</em> option. In case the fields need to be separated,
      if you select <em>Separate Fields</em> = <em>Yes - Upper First</em>, the
      field starting from the first line is the first frame. This is the default
      format in the PAL standard. If instead you select
      <em>Separate Fields</em> = <em>Yes - Lower First</em>, the field starting
      from the second line is the first frame. This is the default format in the
      NTSC standard.<br />
      The recommended interpolation settings for normal use are
      <em>Linear</em> or <em>Cubic</em>. The latter should be the best one, even
      if, in practice, the results are almost the same.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Deinterlace a car in movement (but avoid deinterlacing a static or
        parked car).<a href="" target="_blank"></a>
      </li>
      <li>Deinterlace a person in movement.<a href="" target="_blank"></a></li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        E. B. Bellers and G. de Haan, “Deinterlacing - An overview”, in
        Proceedings of the IEEE, Vol. 86, No. 9, pp. 1839–1857, Sep. 1998.
        <a href="http://dx.doi.org/10.1109/5.705528" target="_blank"
          >http://dx.doi.org/10.1109/5.705528</a
        >
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        Dealing with Interlaced Videos in بـستا: There’s an Exception That Makes
        the Rule!:
        <a
          href="https://blog.ampedsoftware.com/2019/06/04/dealing-with-interlaced-videos-in-amped-five-theres-an-exception-that-makes-the-rule/"
          target="_blank"
          >https://blog.ampedsoftware.com/2019/06/04/dealing-with-interlaced-videos-in-amped-five-theres-an-exception-that-makes-the-rule/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Field-Shift">Field Shift</a></h3>
    <p><em>Aligns the two fields of an interlaced frame.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Field Shift</em> tool allows to relatively shift the two fields of
      an interlaced frame, in order to align the position of an object of
      interest in the output image.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Upper Field Horizontal Shift</strong><br />
        <em>Upper field horizontal shift in pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Lower Field Horizontal Shift</strong><br />
        <em>Lower field horizontal shift in pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Upper Field Vertical Shift</strong><br />
        <em>Upper field vertical shift in pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Lower Field Vertical Shift</strong><br />
        <em>Lower field vertical shift in pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Border Mode</strong><br />
        <em>How the missing border pixels are filled.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Align the fields of a car in movement.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h2><a name="Edit">Edit</a></h2>
    <p><em>Edits image geometric features.</em></p>
    <hr />
    <h3><a name="Crop">Crop</a></h3>
    <p><em>Crops a region of interest of the image.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Crop</em> tool produces an output image which is only the selected
      region of the input image.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Select the area of interest from the current video or image with the
      <em>Selector</em> tool and click on <em>Apply</em>; if you want to change
      the set selection, click on <em>Show Input</em> and then modify it.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Restrict the processing to an area of interest (speed of processing and
        ease of analysis).<a href="" target="_blank"></a>
      </li>
      <li>
        Redact unimportant or sensitive parts of a video.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Demultiplex a space/2d multiplexed video (quad).<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Flip">Flip</a></h3>
    <p><em>Mirrors the image.</em></p>
    <h4>Details</h4>
    <p>The <em>Flip</em> filter mirrors the image in the given direction.</p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Direction</strong><br />
        <em>Direction to flip the image.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Read better a reflected license plate or text.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Correct encoding issues that make the video appear upside-down on
        screen.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Rotate">Rotate</a></h3>
    <p><em>Rotates the image.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Rotate</em> filter rotates the image by the given angle. If the
      rotation angle is not multiple of 90 degrees, the selected interpolation
      algorithm is used, otherwise the original pixel values are only
      transposed.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Angle</strong><br />
        <em>Rotation angle.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Resize Image to Fit</strong><br />
        <em
          >If unchecked, the image remains of the original size, although part
          of the actual data could render outside of the visible area.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Interpolation</strong><br />
        <em>Interpolation algorithm.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Correct images and videos with the wrong orientation.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Rotate an image for easier analysis of a suspect.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Rotate an image to straighten the horizon.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 253–255, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 320–322, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Hsieh Hou and H. Andrews, “Cubic splines for image interpolation and
        digital filtering”, in IEEE Transactions on Acoustics, Speech, and
        Signal Processing, Vol. 26, No. 6, pp. 508–517, December 1978.
        <a href="http://dx.doi.org/10.1109/TASSP.1978.1163154" target="_blank"
          >http://dx.doi.org/10.1109/TASSP.1978.1163154</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Resize">Resize</a></h3>
    <p><em>Resizes the image.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Resize</em> tool interpolates the input image by generating an
      output image of the desired size.<br />
      The available interpolation algorithms are:<br />
      - <em>Nearest</em>: simply copies the value of the closest pixel in the
      position to be interpolated;<br />
      - <em>Bilinear</em>: uses a bilinear interpolation to resample pixel
      data;<br />
      - <em>Bicubic</em>: uses a bicubic interpolation to resample pixel
      data.<br />
      - <em>Area</em> resamples using pixel area relation.<br />
      - <em>Lanczos</em> uses a Lanczos interpolation to resample pixel data.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Size of output image in pixels.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Interpolation</strong><br />
        <em>Interpolation algorithm.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      <em>Nearest</em> is the fastest interpolation algorithm, however it also
      provides the worst visual effect. <em>Bilinear</em> produces better
      results than the previous algorithm, but is a bit slower and may introduce
      some blurriness (new gray levels are introduced in the interpolated
      image). <em>Bicubic</em> is the best of the classical interpolation
      algorithms available (although in most cases you won't probably notice
      visual differences with respect to <em>Bilinear</em>), but it is also the
      slowest. <em>Area</em> may be the preferred method for shrinking as it
      gives moiré-free results; when used for zooming, it is similar to the
      Nearest method. <em>Lanczos</em> produces slightly sharper results than
      <em>Bicubic</em> but takes a little longer to compute.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Improve the readability of a license plate.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Improve the perception of a suspect's face.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Improve the readability of some text.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 253–255, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 320–322, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Hsieh Hou and H. Andrews, “Cubic splines for image interpolation and
        digital filtering”, in IEEE Transactions on Acoustics, Speech, and
        Signal Processing, Vol. 26, No. 6, pp. 508–517, December 1978.
        <a href="http://dx.doi.org/10.1109/TASSP.1978.1163154" target="_blank"
          >http://dx.doi.org/10.1109/TASSP.1978.1163154</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Smart-Resize">Smart Resize</a></h3>
    <p>
      <em
        >Resizes the image with a smart zoom algorithm preserving better
        details.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Smart Resize</em> interpolates the input image by generating an output
      image of the desired size with an iterative two-dimensional implementation
      of the Warped Distance algorithm.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Size of output image in pixels.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Steps</strong><br />
        <em>The number of times the filter is applied.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Strength</strong><br />
        <em>Sharpness of borders and details of the interpolated image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      This filter is slower than normal <em>Resize</em>, but, if properly
      configured, can yield much better results than the <em>Bicubic</em> for
      big enlargement factors. It needs two additional parameters:
      <em>Steps</em> and <em>Strength</em>. <em>Steps</em> is the number of
      times the algorithm is applied to create the image of the desired size. It
      can roughly approximate the filter capability to follow diagonal borders
      instead of creating jagged edges. <em>Strength</em> controls the sharpness
      of the resized image. It can be tuned to adjust the resizing effect on the
      image features.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Improve the readability of a license plate.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Improve the perception of a suspect's face.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Improve the readability of some text.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 253–255, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 320–322, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        G. Ramponi, “Warped distance for space-variant linear image
        interpolation”, in IEEE Transactions on Image Processing, Vol. 8, No. 5,
        pp. 629–639, May 1999.
        <a href="http://dx.doi.org/10.1109/83.760311" target="_blank"
          >http://dx.doi.org/10.1109/83.760311</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Resize-1:1">Resize 1:1</a></h3>
    <p>
      <em
        >Resize the image in order to obtain a 1:1 reproduction on the display
        or on the printed report. Useful for objects such as fingerprints and
        footmarks.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Resize 1:1</em> resizes the image in order to obtain a 1:1
      reproduction on the display or on the printed report. This is useful for
      the reproduction of flat objects such as documents or fingerprints. The
      scale factor is computed by measuring a reference object of known length.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Pixel Distance</strong><br />
        <em>Length, in pixels, of the selected line in the image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>World Distance</strong><br />
        <em>Length of the selected line in the real world.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Unit of Measurement</strong><br />
        <em>The unit in which the number above is expressed.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output DPI</strong><br />
        <em>Resolution of the display device, in DPI.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Interpolation</strong><br />
        <em>Interpolation algorithm.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Display Size</strong><br />
        <em>Length of the display diagonal.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Unit of Measurement (Display)</strong><br />
        <em>The unit in which the number above is expressed.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Display Width (Pixels)</strong><br />
        <em>Horizontal resolution of the display, in pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Display Height (Pixels)</strong><br />
        <em>Vertical resolution of the display, in pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Measure, using the <em>Line</em> tool, an object of known length and type
      its length into the <em>World Distance</em> parameter. Then, select or
      type the resolution of your display device, in dots per inch (DPI). You
      can also calculate the display resolution using the
      <em>Display Calculator</em> tab. Set a resolution of 120 DPI to obtain a
      1:1 reproduction on the PDF report.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Resize a fingerprint, a footprint, or an object to match its real-world
        size.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Frame-Size">Frame Size</a></h3>
    <p><em>Resizes the image canvas.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Frame Size</em> tool pads or crops the input image by generating
      an output image of the desired size. If the image is enlarged, it is
      possible to select the background color and, optionally, to draw a border
      around the original image.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Size of output image in pixels.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Background Color</strong><br />
        <em>Color used to fill the portions outside the original image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Size Presets</strong><br />
        <em>Common sizes</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Horizontal Anchor</strong><br />
        <em>Horizontal position of the original image in the output frame.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Vertical Anchor</strong><br />
        <em>Vertical position of the original image in the output frame.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Horizontal Offset</strong><br />
        <em>Fine tuning of the horizontal position, in pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Vertical Offset</strong><br />
        <em>Fine tuning of the vertical position, in pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Border Color</strong><br />
        <em>Color of the border to draw around the original image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Border Thickness</strong><br />
        <em
          >Thickness of the border in pixels. Setting this parameter to zero
          disables the border.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      In the <em>Canvas</em> tab, choose the desired size of the output image.
      In the <em>Alignment</em> tab, choose the position of the original image
      inside the new frame. The position can be set quickly using the drop-down
      menus and fine-tuned using the sliders. It is possible to draw a border
      around the original image by using the controls in the
      <em>Border</em> tab.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>Add some border to the image.<a href="" target="_blank"></a></li>
      <li>
        Make the canvas larger to avoid some parts going out of the frame with
        stabilization.<a href="" target="_blank"></a>
      </li>
      <li>
        Add space for writing timestamp and notes without covering the picture
        area.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Correct-Perspective">Correct Perspective</a></h3>
    <p>
      <em
        >Removes the perspective effect on a plane of interest in the image
        (image rectification).</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Correct Perspective</em> maps a desired quadrangular region to a
      rectangular one, which corresponds to making the plane of interest
      parallel to the image plane. The pixel values are interpolated with a
      bicubic algorithm. The ratio between width and height of the output
      rectangle can be set by the user by choosing a selection or computed
      automatically from the input points. The automatic computation should only
      be used if the image is not cropped (i.e. the optical axis of the lens
      coincides with the center of the image) and the distortion is not too
      high; in any case, the results of the automatic computation should not be
      relied upon for forensic purposes. The original quadrangular region can be
      refined by selecting again its corners on the rectified image, where they
      are better visible.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Source Points</strong><br />
        <em>Quadrilateral to transform into a rectangle.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Target Selection</strong><br />
        <em>Target rectangle to map the source points to.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Refined Points</strong><br />
        <em
          >Corners of the input quadrilateral visualized on the rectified
          image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The source region is set using the <em>Quadrilateral</em> tool; the
      corners must be set in clockwise order starting from the top-left corner
      (top-left, top-right, bottom-right, bottom-left).<br />
      The destination rectangle can be modified by the <em>Selector</em> tool,
      in order to correct the proportions and the position of the region of
      interest of the image.<br />
      In the <em>Refinement</em> tab, it is possible to improve the accuracy of
      the source region by selecting its corners on the rectified image; the
      refinement can be repeated multiple times if necessary.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Improve the readability of a license plate.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Rectify the street to take some measurements of an accident.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Read the text on a paper photographed on the side.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 320–322, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Hsieh Hou and H. Andrews, “Cubic splines for image interpolation and
        digital filtering”, in IEEE Transactions on Acoustics, Speech, and
        Signal Processing, Vol. 26, No. 6, pp. 508–517, December 1978.
        <a href="http://dx.doi.org/10.1109/TASSP.1978.1163154" target="_blank"
          >http://dx.doi.org/10.1109/TASSP.1978.1163154</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Aspect-Ratio">Aspect Ratio</a></h3>
    <p><em>Corrects the aspect ratio of a video.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Aspect Ratio</em> filter interpolates the pixels of a video to
      restore the original ratio between horizontal and vertical resolution,
      which has been distorted during the conversion of the signal from the
      analog to the digital format.<br />
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Output Aspect Ratio</strong><br />
        <em
          >The Aspect Ratio of the output image, expressed as a fractional
          number.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em>The dimension to keep fixed.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Interpolation</strong><br />
        <em>Interpolation algorithm.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        Introduction to Aspect Ratio:
        <a
          href="https://blog.ampedsoftware.com/2016/03/14/introduction-to-aspect-ratio/"
          target="_blank"
          >https://blog.ampedsoftware.com/2016/03/14/introduction-to-aspect-ratio/</a
        >
      </li>
      <li>
        Aspect Ratio – Understanding the Information and Using the Filter:
        <a
          href="https://blog.ampedsoftware.com/2016/03/17/aspect-ratio-understanding-the-information-and-using-the-filter/"
          target="_blank"
          >https://blog.ampedsoftware.com/2016/03/17/aspect-ratio-understanding-the-information-and-using-the-filter/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Undistort">Undistort</a></h3>
    <p>
      <em
        >Corrects the geometric distortion caused by capturing optics (barrel
        and pin-cushion lens distortion). Supports the selection of multiple
        lines for the estimation of the curvature to compensate.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Undistort</em> corrects the geometric distortion caused by capturing
      devices' optics. Although distortion can be irregular or follow many
      patterns, the most commonly encountered distortions are radially
      symmetric, or approximately so, arising from the symmetry of a
      photographic lens. In practice, distortion causes straight lines to appear
      curved in the image: this effect grows when going away from the center of
      the image.<br />
      The optics distortion can usually be classified as one of two main
      types:<br />
      - the barrel distortion is associated with wide angle (or minimal zoom)
      lenses and it makes the images to appear spherical (curved outward);<br />
      - the pincushion distortion is associated with telephoto lenses (or
      maximum zoom); the images appear bent inwards, towards the center of the
      image.<br />
      The output image is resampled using the interpolation method specified by
      the <em>Interpolation</em> parameter.<br />
      The center of the image must coincide with the optical axis of the lens
      (i.e. the filter cannot be applied to cropped images).
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em
          >Algorithm used to approximate the mapping function of the lens. The
          best algorithm depends on the kind of optics.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Distortion</strong><br />
        <em
          >Correction coefficient. For the Barrel distortion the coefficient is
          < 0, while > 0 for the Pincushion one.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Canvas Size</strong><br />
        <em>Enlargement factor for the image canvas.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Interpolation</strong><br />
        <em>Interpolation algorithm.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Distortion Computation</strong><br />
        <em
          >Switch between manual adjustment of the distortion parameter (using
          the slider) or automatic computation (using the lines, if
          available).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Points on Line 1</strong><br />
        <em
          >Optional: 3 or more points that are aligned on a straight line in the
          real world.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Points on Line 2</strong><br />
        <em
          >Optional: 3 or more points that are aligned on a straight line in the
          real world.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Points on Line 3</strong><br />
        <em
          >Optional: 3 or more points that are aligned on a straight line in the
          real world.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The <em>Distortion</em> parameter can be either adjusted manually or
      computed automatically. For automatic computation, switch to the
      <em>Line 1</em> tab and select, using the <em>Curve</em> tool, a line made
      of at least 3 points that is straight in the real world. Up to 3 lines can
      be selected, using also the <em>Line 2</em> and <em>Line 3</em> tabs.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Correct the distortion in an unknown CCTV camera to view better facial
        features.<a href="" target="_blank"></a>
      </li>
      <li>
        Correct the distortion before taking a measurement.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 320–322, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Hsieh Hou and H. Andrews, “Cubic splines for image interpolation and
        digital filtering”, in IEEE Transactions on Acoustics, Speech, and
        Signal Processing, Vol. 26, No. 6, pp. 508–517, December 1978.
        <a href="http://dx.doi.org/10.1109/TASSP.1978.1163154" target="_blank"
          >http://dx.doi.org/10.1109/TASSP.1978.1163154</a
        >
      </li>
      <li>
        Duane C. Brown, “Decentering distortion of lenses”, in Photogrammetric
        Engineering, Vol. 32, No. 3, pp. 444–462, May 1966.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Bernd Jähne, “Digital Image Processing”, 6th revised and extended
        edition, Springer-Verlag Berlin Heidelberg 2005. ISBN: 3-540-24035-7.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Correct-Fisheye">Correct Fisheye</a></h3>
    <p>
      <em
        >Compensate the distortion of common fisheye lenses. Supports the
        selection of multiple lines for the estimation of the curvature to
        compensate.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Correct Fisheye</em> tool corrects the distortion caused by the
      most common types of fisheye lenses. The parameter
      <em>Mapping Function</em> must be set according to the specifications of
      the lens given by the producer: if configured correctly, it can properly
      compensate even strong distortions within the entire image.<br />
      The output image is resampled using the interpolation method specified by
      the <em>Interpolation</em> parameter.<br />
      It is possible to enlarge the image canvas by using the
      <em>Canvas Size</em> parameter.<br />
      The center of the image must coincide with the optical axis of the lens
      (i.e. the filter cannot be applied to cropped images).
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Mapping function</strong><br />
        <em
          >Algorithm used to describe the mapping function of the lens,
          according to its technical specifications.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Focal Length</strong><br />
        <em>Focal length relative to the image width.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Field of View</strong><br />
        <em>Horizontal field of view in degrees.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Canvas Size</strong><br />
        <em>Enlargement factor for the image canvas.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Interpolation</strong><br />
        <em>Interpolation algorithm.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Focal Length Computation</strong><br />
        <em
          >Switch between manual adjustment of the focal length (using the
          slider) or automatic computation (using the lines, if available).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Points on Line 1</strong><br />
        <em
          >Optional: 3 or more points that are aligned on a straight line in the
          real world.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Points on Line 2</strong><br />
        <em
          >Optional: 3 or more points that are aligned on a straight line in the
          real world.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Points on Line 3</strong><br />
        <em
          >Optional: 3 or more points that are aligned on a straight line in the
          real world.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Longitude Correction (degrees)</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Latitude Correction (degrees)</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Rotation (degrees)</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The <em>Focal Length</em> parameter can be either adjusted manually or
      computed automatically. For automatic computation, switch to the
      <em>Line 1</em> tab and select, using the <em>Curve</em> tool, a line made
      of at least 3 points that is straight in the real world. Up to 3 lines can
      be selected, using also the <em>Line 2</em> and <em>Line 3</em> tabs. The
      <em>Mapping Function</em> is a property of the fisheye lens and is usually
      found in the technical specifications. If you don't know the mapping
      function, try them all until you find the one that produces the best
      correction (i.e. straightens most of the lines in the image).
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Correct the distortion of a specific optic.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Correct the distortion before taking a measurement.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 320–322, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Hsieh Hou and H. Andrews, “Cubic splines for image interpolation and
        digital filtering”, in IEEE Transactions on Acoustics, Speech, and
        Signal Processing, Vol. 26, No. 6, pp. 508–517, December 1978.
        <a href="http://dx.doi.org/10.1109/TASSP.1978.1163154" target="_blank"
          >http://dx.doi.org/10.1109/TASSP.1978.1163154</a
        >
      </li>
      <li>
        Kenro Miyamoto, “Fish Eye Lens”, in Journal of the Optical Society of
        America, Vol. 54, No. 8, pp. 1060–1061, 1964.
        <a href="http://dx.doi.org/10.1364/JOSA.54.001060" target="_blank"
          >http://dx.doi.org/10.1364/JOSA.54.001060</a
        >
      </li>
      <li>
        D. Schneider, E. Schwalbe and H.-G. Maas, “Validation of geometric
        models for fisheye lenses”, in ISPRS Journal of Photogrammetry and
        Remote Sensing, Vol. 64, No. 3, pp. 259–266, May 2009.
        <a
          href="http://dx.doi.org/10.1016/j.isprsjprs.2009.01.001"
          target="_blank"
          >http://dx.doi.org/10.1016/j.isprsjprs.2009.01.001</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Unroll">Unroll</a></h3>
    <p><em>Converts an omnidirectional image into a panoramic one.</em></p>
    <h4>Details</h4>
    <p>
      <em>Unroll</em> maps the original image to the output image in order to
      convert a hemispherical image into a standard one.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Start Angle</strong><br />
        <em>The angle at which the input image is cut.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Interpolation</strong><br />
        <em>Interpolation algorithm.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        View a 360 degree image as panoramic.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 320–322, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Hsieh Hou and H. Andrews, “Cubic splines for image interpolation and
        digital filtering”, in IEEE Transactions on Acoustics, Speech, and
        Signal Processing, Vol. 26, No. 6, pp. 508–517, December 1978.
        <a href="http://dx.doi.org/10.1109/TASSP.1978.1163154" target="_blank"
          >http://dx.doi.org/10.1109/TASSP.1978.1163154</a
        >
      </li>
    </ul>
    <hr />
    <h2><a name="Channels">Channels</a></h2>
    <p><em>Color conversion and extraction functions.</em></p>
    <hr />
    <h3><a name="Grayscale-Conversion">Grayscale Conversion</a></h3>
    <p><em>Converts the image to grayscale.</em></p>
    <h4>Details</h4>
    <p>
      <em>Grayscale Conversion</em> produces a single channel (grayscale) image
      from a 3-channels (usually RGB-color) image.<br />
      Each pixel value, Y, of the output image is calculated with the following
      formula:<br />
      Y = 0.299*R + 0.587*G + 0.114*B,<br />
      where R, G and B are respectively the red, green, and blue values of the
      pixel in the input image.<br />
      If the input image is already in grayscale, the output image will be a
      simple copy of the input one.
    </p>
    <h4>Parameters</h4>
    <em>This filter has no parameters.</em>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Improve the perceived image quality (does a bit of denoising).<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Remove color information for a better face comparison.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Avoid being distracted by color artifacts.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, p. 71, 1989. ISBN: 0-13-336165-9.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Color-Conversion">Color Conversion</a></h3>
    <p>
      <em
        >Converts the image from grayscale to RGB, cloning the three
        channels.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Color Conversion</em> produces a 3-channels (RGB) image from a single
      channel (grayscale) image by making three copies of the input one.<br />
      If the input is already a multi-channel image, the output will be a simple
      copy of the input image.
    </p>
    <h4>Parameters</h4>
    <em>This filter has no parameters.</em>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Add colored annotations on a grayscale image.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Color-Switch">Color Switch</a></h3>
    <p>
      <em
        >Exchanges R and B color channels in the image, to correct wrong colors
        in video.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Color Switch</em> swaps the red and blue channels of image, an
      operation that may be necessary for some defective video files.<br />
      If the input image is grayscale, the output image will be a simple copy of
      the input one.
    </p>
    <h4>Parameters</h4>
    <em>This filter has no parameters.</em>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Correct a CCTV video where R and B channels are inverted.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Extract-Channel">Extract Channel</a></h3>
    <p>
      <em
        >Extracts a single channel from the image. The output image has one
        channel.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Extract Channel</em> produces a single channel (grayscale) image from
      a 3-channels (RGB) extracting the channel of interest from the input
      image.<br />
      It is possible to convert the image into another color space before the
      extraction; the currently available options, besides the original
      <em>RGB</em>, are: <em>YCbCr</em>, <em>YUV</em>, <em>HSV</em>,
      <em>HLS</em>, <em>XYZ</em>, <em>Lab</em>, <em>Luv</em> and <em>CMYK</em>.
      For example, if the <em>YCbCr Y</em> channel is selected, the image is
      converted into the YCbCr color space and the Y is copied to the output
      image. The currently implemented <em>RGB</em> to <em>CMYK</em> conversion
      is a simplified one that does not use color profiles.<br />
      If the input image has only one channel, the output image will be a simple
      copy of the input one.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Channel</strong><br />
        <em
          >The channel of interest to be extracted, corresponding to one of the
          components of the color space.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      <em>Extract Channel</em> could be used to process an image in a color
      space different from the input one.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Extract only the luma or the G channel from a dark noisy CCTV video.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, p. 71, 1989. ISBN: 0-13-336165-9.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        Extracting Channels:
        <a
          href="https://blog.ampedsoftware.com/2018/07/02/extracting-channels/"
          target="_blank"
          >https://blog.ampedsoftware.com/2018/07/02/extracting-channels/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Enable-Channels">Enable Channels</a></h3>
    <p>
      <em
        >Displays only the selected color channels in the image. The output
        image has three channels.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Enable Channels</em> filter displays an RGB image by rendering only
      the channels that have been selected. If one or more channels are
      selected, the output image is a combination of them. Otherwise, the
      resulting image is black.<br />
      If the input image is grayscale, the output image will be a copy of the
      input.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Red</strong><br />
        <em>Color channel to be rendered.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Green</strong><br />
        <em>Color channel to be rendered.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Blue</strong><br />
        <em>Color channel to be rendered.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Remove a noisy channel (usually the blue).<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Replace-Channel">Replace Channel</a></h3>
    <p><em>Replaces one color channel of the image with another.</em></p>
    <h4>Details</h4>
    <p>
      <em>Replace Channel</em> converts the image into another color space
      selected by the user and replaces one of the channels with another,
      possibly from a third color space. The currently available options,
      besides the original RGB, are: YCbCr, YUV, HSV, HLS, XYZ, Lab, Luv and
      CMYK. The currently implemented RGB to CMYK conversion is a simplified one
      that does not use color profiles. It is optionally possible to invert the
      replaced channel or to fill it with black, middle gray or white.<br />
      If the input image has only one channel, the output image will be a simple
      copy of the input one.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Original Channel</strong><br />
        <em>The channel of the input image that will be replaced.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Replacement Channel</strong><br />
        <em
          >The channel whose contents will replace the
          <em>Original Channel</em>, optionally after a transformation
          determined by the <em>Processing</em> parameter.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Processing</strong><br />
        <em>Optional processing of the <em>Replacement Channel</em>.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      <em>Replace Channel</em> may sometimes be useful to improve the visibility
      of details in an image.
    </p>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, p. 71, 1989. ISBN: 0-13-336165-9.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h2><a name="Adjust">Adjust</a></h2>
    <p><em>Adjusts image values.</em></p>
    <hr />
    <h3><a name="Contrast-Brightness">Contrast Brightness</a></h3>
    <p><em>Adjusts the contrast and brightness values of the image.</em></p>
    <h4>Details</h4>
    <p>
      <em>Contrast Brightness</em> maps input image values to output image
      values according to a linear transformation. The mapping involves two
      operations: multiplication and addition with constants respectively
      controlled by the <em>Contrast</em> and <em>Brightness</em> parameters.
      Increasing (or reducing) the <em>Contrast</em> makes the difference
      between light and dark areas appears sharper (or smoother). Similarly,
      increasing (or decreasing) the <em>Brightness</em> makes the overall image
      appear lighter (or darker). These changes can improve the definition of
      excessively dark or light areas in the image, but will tend to saturate
      the image if taken too far.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Contrast</strong><br />
        <em>Extends the intensity difference among pixel (linear gain).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Brightness</strong><br />
        <em>Adds or subtracts an offset to image pixels (bias).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em
          >The domain in which the image is mapped. The <em>Linear</em> mode is
          the classical one. The <em>Logarithmic</em> mode keeps the black and
          white points unchanged and therefore prevents saturation.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Lookup Table</strong><br />
        <em>The lookup table generated with the current settings.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      <em>Contrast Brightness</em> filter can be used to improve
      underexposed/overexposed images. It provides little (if any) help in
      distinguishing low-contrast objects from their surroundings.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Improve the visibility of a license plate.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>Improve the visibility of a face.<a href="" target="_blank"></a></li>
      <li>
        Increase the constrast of facial features for a better comparison.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 234–241, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Vasile Pătraşcu and Vasile Buzuloiu, “The affine transforms for image
        enhancement in the context of logarithmic models”, in Proceedings of the
        International Conference on Computer Vision and Graphics, Vol. 2, pp.
        596–601, September 2002.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Exposure">Exposure</a></h3>
    <p><em>Adjusts the image exposure.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Exposure</em> tool performs a non-linear mapping of the input
      image values. It adjusts the image gamma applying a power function that
      has three parameters: <em>Exposure</em>, <em>Offset</em> and
      <em>Recover</em>. <em>Exposure</em> modifies the pixel values in the
      midtone-to-white range with minimal effect in the extreme shadows.
      Decreasing (respectably increasing) the <em>Offset</em> darkens (resp.
      lightens) the pixel values in the midtone-to-black range with minimal
      effect on the highlights. <em>Recover</em> controls the overall brightness
      of the image.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Exposure</strong><br />
        <em>Adjusts the exposure of the image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Offset</strong><br />
        <em>Adds or subtracts an offset to the pixel values.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Recover</strong><br />
        <em>Recovers the saturated pixels of the image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Lookup Table</strong><br />
        <em>The lookup table generated with the current settings.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The <em>Exposure</em> filter can be used to improve images that look
      either bleached out or too dark (not properly exposed).
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Improve the visibility of a license plate in a very dark video.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Improve the visibility of a face in backlight.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 234–241, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Hue-Saturation-Value">Hue Saturation Value</a></h3>
    <p>
      <em
        >Adjusts the hue, the saturation and the color values of the image.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Hue Saturation Value</em> tool adjusts image pixel values in the
      HSV color space, where: <em>Hue</em>, H, is the visual sensation that
      corresponds to the color tone; <em>Saturation</em>, S, refers to the color
      purity, this means how vibrant or rich the color is; <em>Value</em>, V, is
      the brightness.<br />
      The input image is first converted from RGB to HSV color space, then the
      HSV value of each pixel of the image is modified according to the
      parameters. The resulting image is finally converted back to the RGB color
      space.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Hue</strong><br />
        <em
          >Adds or subtracts a constant to the hue of the image. It adjusts the
          offset of a linear mapping.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Saturation</strong><br />
        <em
          >Multiplies by a constant the saturation of the image. It adjusts the
          slope of a linear mapping.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Value</strong><br />
        <em
          >Adds or subtracts a constant to the value of the image. It adjusts
          the offset of a linear mapping.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Adjust the colors of an object to better reflect the real scene.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Desaturate color to attenuate the impact of color artifacts.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 60–71, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 234–241, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Curves">Curves</a></h3>
    <p>
      <em
        >Adjusts the tone values following a smooth curve defined by control
        points. Supports independent modification of intensity and the RGB
        channels and multiple interpolation modes.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Curves</em> filter maps the input image values to the output image
      values according to the drawn curve: the x coordinate of the curve is
      mapped to the corresponding y value. Every RGB channel of the image is
      processed according to the respective color curve. Then all the channels
      are also processed in the same way according to the <em>Value</em> curve.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Value</strong><br />
        <em>Points representing the value transformation curve.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Red</strong><br />
        <em>Points representing the red transformation curve.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Green</strong><br />
        <em>Points representing the green transformation curve.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Blue</strong><br />
        <em>Points representing the blue transformation curve.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em>Interpolation mode for the intensity curve.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The curve can be edited using the control points. To add a point,
      left-click on the curve. To move a control point, drag it to the desired
      position holding the left mouse button down. To delete a point,
      right-click on it.<br />
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Improve the visibility of a license plate.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>Improve the visibility of a face.<a href="" target="_blank"></a></li>
      <li>Correct an underwater image.<a href="" target="_blank"></a></li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 234–241, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Parametric-Curves">Parametric Curves</a></h3>
    <p>
      <em
        >Adjusts the tone values by setting the gain in four portions of the
        luminance range.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Parametric Curves</em> filter maps the input image values to the
      output image values according to a curve generated using the sliders. The
      sliders determine the slope of the curve in four zones of the input
      luminance range: <em>Highlights</em>, <em>Lights</em>, <em>Darks</em> and
      <em>Shadows</em>.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Curve</strong><br />
        <em>The curve generated with the current settings.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Highlights</strong><br />
        <em>Adjustment for the highlights.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Lights</strong><br />
        <em>Adjustment for the lights.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Darks</strong><br />
        <em>Adjustment for the darks.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Shadows</strong><br />
        <em>Adjustment for the shadows.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Use the sliders to adjust the shape of the curve. The range of values that
      can be obtained using the current slider will appear shaded on the graph.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Improve the visibility of a license plate.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>Improve the visibility of a face.<a href="" target="_blank"></a></li>
      <li>
        Increase the constrast of facial features for a better comparison.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Levels">Levels</a></h3>
    <p><em>Adjusts intensity and color levels.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Levels</em> filter maps the values of the input image to the
      values of output image according to a piece-wise linear transformation
      controlled by the values of <em>Highlights</em>, <em>Midtones</em> and
      <em>Shadows</em>. The <em>Midtones</em> slider changes the intensity
      values of the middle range of intensity levels without significantly
      changing the highlights and shadows in the image. The
      <em>Highlights</em> and <em>Shadows</em> sliders set the black point and
      the white point of the image. Each channel of the input image is
      configured using the sliders of the corresponding parameter:
      <em>Value</em>, <em>Red</em>, <em>Green</em> or <em>Blue</em>. For each
      parameter, the histogram of the tonal range of the input image is
      displayed. If the input image is in grayscale, changing the setting of
      <em>Red</em>, <em>Green</em> and <em>Blue</em> parameters has no effect on
      the output image.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Value</strong><br />
        <em
          ><em>Highlights</em>, <em>Midtones</em> and <em>Shadows</em> settings
          used to map the pixel values of the grayscale converted image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Red</strong><br />
        <em
          ><em>Highlights</em>, <em>Midtones</em> and <em>Shadows</em> settings
          used to map the pixel values of the red channel of image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Green</strong><br />
        <em
          ><em>Highlights</em>, <em>Midtones</em> and <em>Shadows</em> settings
          used to map the pixel values of the blue channel of image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Blue</strong><br />
        <em
          ><em>Highlights</em>, <em>Midtones</em> and <em>Shadows</em> settings
          used to map the pixel values of the green channel of image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Improve the visibility of a license plate.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>Improve the visibility of a face.<a href="" target="_blank"></a></li>
      <li>
        Increase the constrast of facial features for a better comparison.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 234–241, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Histogram-Equalization">Histogram Equalization</a></h3>
    <p>
      <em
        >Improves the image contrast by uniformly distributing the pixel values.
        Supports the optimization of a specific region of the image.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Histogram Equalization</em> filter adjusts the image tones by
      distributing the pixel values more uniformly across the available
      range.<br />
      It is possible to use one of the two equalization modes:<br />
      - <em>Intensity</em>: the equalization is applied to the overall image
      luminance by processing the image in the YCrCb color space;<br />
      - <em>Colors</em>: the equalization is independently performed on the
      three RGB channels.<br />
      For grayscale images there is no difference in using the
      <em>Intensity</em> or the <em>Colors</em> mode. It is optionally possible
      to ignore black pixels in the computation; this may improve the rendition
      of images that contain a black border.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em>Type of adjustment to be done.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Ignore Black Pixels</strong><br />
        <em
          >Optionally ignore black pixels in the computation. This may improve
          the rendition of images that contain a black border.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Lookup Table</strong><br />
        <em>The lookup table generated with the current settings.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Improve the visibility of a license plate.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>Improve the visibility of a face.<a href="" target="_blank"></a></li>
      <li>Correct an underwater image.<a href="" target="_blank"></a></li>
      <li>
        Maximize the contrast to highlight some weak detail or variation.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Extract hidden dots from a printed document.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Improve the visibility a person behind a glass.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 241–244, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Contrast-Stretch">Contrast Stretch</a></h3>
    <p>
      <em
        >Improves the image contrast by expanding the range of intensity values.
        Supports a sensitivity threshold to tune the filter effect.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Contrast Stretch</em> filter adjusts the image values expanding
      the pixel values across the whole available range.<br />
      Two stretching modes are available:<br />
      - <em>Intensity</em>: the stretch is applied to the overall image
      luminance by processing the image in the YCrCb color space;<br />
      - <em>Colors</em>: the stretch is independently performed on the three RGB
      channels.<br />
      For grayscale images there is no difference in using the
      <em>Intensity</em> or the <em>Colors</em> mode.<br />
      If the parameter <em>Sensitivity</em> is greater than zero, a percentage
      equal to <em>Sensitivity</em> of the darkest and brightest pixels is
      discarded before the stretching.<br />
      If the range of the input image values already covers the whole tonal
      range (0-255) and <em>Sensitivity</em> is equal to zero, the filter has no
      effect.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em>Type of adjustment to perform.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Sensitivity</strong><br />
        <em
          >The percentage of pixels to exclude in the computation of the tonal
          range.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Lookup Table</strong><br />
        <em>The lookup table generated with the current settings.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Contrast Stretch can be used to enhance features in low-contrast images.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Improve the visibility of a license plate.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>Improve the visibility of a face.<a href="" target="_blank"></a></li>
      <li>
        Increase the constrast of facial features for a better comparison.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, p. 235, 1989. ISBN: 0-13-336165-9.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Temperature-Tint">Temperature Tint</a></h3>
    <p>
      <em
        >Manually adjusts the dominant color temperature and tint in the
        scene.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Temperature Tint</em> method allows to change the dominant color
      of an image by manually adjusting the
      <em>Color Temperature</em> (orange-blue) and <em>Tint</em> (purple-green).
      With the default setting, the selected color is mapped to 6500K white (as
      specified by most image and video standards) and is therefore removed from
      the image; e.g. increasing the <em>Color Temperature</em> will make the
      image less blue and more orange. The opposite behavior can be obtained by
      setting the <em>Mode</em> to <em>Map White to Selected Color</em>. In this
      way, 6500K white is mapped to the selected color; e.g. increasing the
      <em>Color Temperature</em> will make the image more blue. In both cases,
      the colors are processed using the CAT02 chromatic adaptation transform
      used in the CIECAM02 color appearance model. The overall image can be made
      brighter or darker by adjusting the
      <em>Exposure Correction</em> parameter; if this parameter is 0, the
      average luminance (XYZ Y) of the image remains unchanged. If the input
      image is grayscale, only the <em>Exposure Correction</em> is performed.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Exposure Correction (EV)</strong><br />
        <em>Adjusts the overall brightness of the image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Color Temperature (Kelvin)</strong><br />
        <em
          >Color temperature used for Temperature Tint correction. Low = orange,
          6500 = white, high = blue.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Tint Correction (Δuv percent)</strong><br />
        <em
          >Color tint used for Temperature Tint correction. Negative = purple,
          positive = green.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em>The way the filter proceeds.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Correct the color cast given by illumination or wrong camera settings.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        N. Moroney, M. D. Fairchild, R. W. G. Hunt, C. Li, M. Ronnier Luo and T.
        Newman, “The CIECAM02 Color Appearance Model”, in Proceedings of the
        IS&T/SID Tenth Color and Imaging Conference, pp. 23–27, 2002.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        The Temperature Tint Filter:
        <a
          href="https://blog.ampedsoftware.com/2017/06/29/the-temperature-tint-filter/"
          target="_blank"
          >https://blog.ampedsoftware.com/2017/06/29/the-temperature-tint-filter/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="White-Balance">White Balance</a></h3>
    <p>
      <em
        >Adjusts an image in order to make neutral objects appear gray or
        white.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>White Balance</em> filter performs a global adjustment that maps
      the average color of the image to neutral gray, according to the “Gray
      World” model. In some cases, this can effectively correct an improper
      white balance setting of the camera. If a selection is set in the
      <em>Selection</em> tab, the average color of the selection is mapped to
      neutral gray. It is optionally possible to adjust the overall brightness
      of the image.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Color Space</strong><br />
        <em>The color space in which the processing is performed.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Exposure Correction (EV)</strong><br />
        <em>Adjusts the overall brightness of the image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The processing can be performed either by scaling the three
      <em>RGB</em> channels of the input image, or by applying the
      <em>CAT02</em> chromatic adaptation transform used in the CIECAM02 color
      appearance model. <em>CAT02</em> is more accurate but requires a slightly
      longer processing time; differences between <em>RGB</em> and
      <em>CAT02</em> are often barely noticeable, unless the image contains very
      saturated colors. If a selection is set in the <em>Selection</em> tab, the
      average color of the selection is mapped to neutral gray. Therefore, the
      <em>Selection</em> should be used to pick a gray object in the scene if
      available. The overall image can be made brighter or darker by adjusting
      the <em>Exposure Correction</em> parameter; if this parameter is 0, the
      average luminance (XYZ Y) of the image or the selection remains unchanged.
      If the input image is grayscale, only the <em>Exposure Correction</em> is
      performed.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Correct the color cast given by illumination or wrong camera settings.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        N. Moroney, M. D. Fairchild, R. W. G. Hunt, C. Li, M. Ronnier Luo and T.
        Newman, “The CIECAM02 Color Appearance Model”, in Proceedings of the
        IS&T/SID Tenth Color and Imaging Conference, pp. 23–27, 2002.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="CLAHE">CLAHE</a></h3>
    <p>
      <em
        >Applies a contrast limited histogram equalization, useful on images
        with high dynamic range (both very dark and very bright areas).</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>CLAHE</em> filter adjusts the image values by dividing the image
      in <em>Size</em>x<em>Size</em> pixel blocks and applying histogram
      equalization to each block independently. In order to avoid noise
      amplification, contrast limiting is applied: if the fraction of pixels in
      any histogram bin is above the value <em>Limit</em>, those pixels are
      clipped and distributed uniformly to other bins before applying histogram
      equalization. After equalization, to remove artifacts in tile borders,
      bilinear interpolation is applied.<br />
      It is possible to use one of the two equalization modes:<br />
      - <em>Intensity</em>: the equalization is applied to the overall image
      luminance by processing the image in the YCrCb color space;<br />
      - <em>Colors</em>: the equalization is independently performed on the
      three RGB channels.<br />
      For grayscale images there is no difference in using the
      <em>Intensity</em> or the <em>Colors</em> mode.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em>Type of adjustment to be done.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Size of image blocks for filtering.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Limit</strong><br />
        <em>Clip limit to avoid noise amplification.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Improve the contrast on indoor/outdoor images.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        K. Zuiderveld, “Contrast Limited Adaptive Histogram Equalization”, in
        Graphics Gems IV, Paul S. Heckbert Ed., Academic Press 1994. ISBN:
        0-12-336155-9.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Homomorphic-Filter">Homomorphic Filter</a></h3>
    <p>
      <em
        >Adjusts separately the contrast of the illumination and detail in an
        image.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Homomorphic Filter</em> is a classical image processing tool. It
      separates the low frequencies (illumination) and high frequencies (detail)
      of an image and adjusts separately their contrast. Typically, the contrast
      of the illumination is reduced, in order to make the dark portions
      brighter and therefore more visible. This filter can produce better
      results than <em>Contrast Brightness</em> because it does not attenuate
      the details in the image, and can optionally enhance them. As a drawback,
      it can introduce halos around the edges of the objects.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Alpha</strong><br />
        <em
          >A parameter of the filter that separates the low and high frequencies
          of the image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Low Frequency Contrast</strong><br />
        <em
          >Reducing this parameter makes the dark portions of the image
          brighter.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>High Frequency Contrast</strong><br />
        <em
          >Increasing this parameter makes the details of the image more
          visible.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Gain (EV)</strong><br />
        <em>Adjusts the overall brightness of the image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      When the <em>Contrast</em> sliders are both set to 1, the filter leaves
      the image unchanged. Try reducing the <em>Low Frequency Contrast</em> in
      order to make the dark portions more visible. Then, try increasing the
      <em>High Frequency Contrast</em> in order to enhance the details. You can
      adjust the overall brightness of the image by using the
      <em>Gain</em> slider. The <em>Alpha</em> parameter adjusts the boundary
      between low and high frequencies; higher values produce an output image
      with richer details but can introduce halos around the edges of the
      objects.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>Correct uneven illumination.<a href="" target="_blank"></a></li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Alan V. Oppenheim, Ronald W. Schafer and Thomas G. Stockham, Jr.,
        “Nonlinear Filtering of Multiplied and Convolved Signals”, in
        Proceedings of the IEEE, Vol. 56, No. 8, pp. 1264–1291, August 1968.
        <a href="http://dx.doi.org/10.1109/PROC.1968.6570" target="_blank"
          >http://dx.doi.org/10.1109/PROC.1968.6570</a
        >
      </li>
      <li>
        Thomas G. Stockham, Jr., “Image Processing in the Context of a Visual
        Model”, in Proceedings of the IEEE, Vol. 60, No. 7, pp. 828–842, July
        1972.
        <a href="http://dx.doi.org/10.1109/PROC.1972.8782" target="_blank"
          >http://dx.doi.org/10.1109/PROC.1972.8782</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Retinex">Retinex</a></h3>
    <p>
      <em
        >Corrects an uneven illumination in the image using the Retinex
        algorithm.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Retinex</em> filter was specifically developed in order to remove
      an uneven illumination from the image. It also enhances high-contrast
      images, making the dark portions more visible. بـستا uses an improved
      version of the “spiral path” algorithm described in (Frankle and McCann,
      1983). If the input image is grayscale, only the contrast is adjusted.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Iterations</strong><br />
        <em
          >How many times the Retinex filter is applied. Higher values produce a
          higher contrast but can introduce halos near sharp edges.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The <em>Iterations</em> parameter adjusts how many times the filter is
      applied; more iterations produce a higher-contrast output image but can
      introduce dark halos near the sharp edges.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>Correct uneven illumination.<a href="" target="_blank"></a></li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        J. A. Frankle and J. J. McCann, “Method and apparatus for lightness
        imaging”, US Patent No. 4,384,336 (1983).
        <a
          href="http://patft1.uspto.gov/netacgi/nph-Parser?patentnumber=4384336"
          target="_blank"
          >http://patft1.uspto.gov/netacgi/nph-Parser?patentnumber=4384336</a
        >
      </li>
    </ul>
    <hr />
    <h3>
      <a name="Automatic-Color-Equalization">Automatic Color Equalization</a>
    </h3>
    <p>
      <em
        >Reduces color casts and adjusts the contrast using the Automatic Color
        Equalization (ACE) algorithm.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Automatic Color Equalization</em> (ACE) algorithm, described in
      (Rizzi, Gatta and Marini, 2003), performs a space-varying processing that
      removes color casts and adjusts the contrast. This method can effectively
      balance the colors of an image illuminated by multiple light sources and
      reduce the contrast of images with very bright and very dark areas
      simultaneously. بـستا uses the piecewise linear interpolation method
      described in (Getreuer, 2012). A <em>Global</em> method, that replaces the
      spatial filtering with a global average, is also available; it has a
      significantly lower computational cost but may reduce the visibility of
      fine details. This global processing is equivalent to a “smoothed”
      histogram equalization in which the image histogram is smoothed with a
      moving average and then equalized.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Method</strong><br />
        <em>Filtering method used in the piecewise linear approximation.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Strength</strong><br />
        <em>Strength of the filter. Higher values produce a stronger effect.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Lookup Table (Global)</strong><br />
        <em
          >The lookup table generated with the current settings (Global mode
          only).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The filter can be computed using either a
      <em>Discrete Fourier Transform</em> (DFT) or a
      <em>Discrete Cosine Transform</em> (DCT); the DCT is slower but produces
      higher-quality results. A <em>Global</em> method is also available; it has
      a significantly lower computational cost but may reduce the visibility of
      fine details. The <em>Strength</em> parameter acts as a contrast tuner:
      higher values produce a stronger equalization of the colors and contrast.
      If the input image is grayscale, only the contrast is affected.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Correct the color cast given by illumination or wrong camera settings.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        A. Rizzi, C. Gatta and D. Marini, “A new algorithm for unsupervised
        global and local color correction”, in Pattern Recognition Letters, Vol.
        24, No. 11, pp. 1663–1677, July 2003.
        <a
          href="http://dx.doi.org/10.1016/S0167-8655(02)00323-9"
          target="_blank"
          >http://dx.doi.org/10.1016/S0167-8655(02)00323-9</a
        >
      </li>
      <li>
        Pascal Getreuer, “Automatic Color Enhancement (ACE) and its Fast
        Implementation”, in Image Processing On Line, Vol. 2, pp. 266–277, 2012.
        <a href="http://dx.doi.org/10.5201/ipol.2012.g-ace" target="_blank"
          >http://dx.doi.org/10.5201/ipol.2012.g-ace</a
        >
      </li>
    </ul>
    <hr />
    <h2><a name="Extract">Extract</a></h2>
    <p><em>Extracts and analyzes image features.</em></p>
    <hr />
    <h3><a name="Negative">Negative</a></h3>
    <p><em>Negative of the image.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Negative</em> tool calculates the negative of the image, by
      subtracting the value of each pixel to the maximum intensity value (255).
    </p>
    <h4>Parameters</h4>
    <em>This filter has no parameters.</em>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Improve the readability of a license plate or some text.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, p. 238, 1989. ISBN: 0-13-336165-9.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Threshold">Threshold</a></h3>
    <p>
      <em
        >Thresholds the image values to the desired values. Supports several
        thresholding modes.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Threshold</em> tool applies the following formula to each pixel
      value of the input image:<br />
      - For <em>Mode</em> = <em>Binary</em>:<br />
      if <em>Low Threshold</em> < Input < <em>High Threshold</em><br />
      then Output = 255<br />
      otherwise Output = 0;<br />
      if <em>High Threshold</em> < Input < <em>Low Threshold</em><br />
      then Output = 0<br />
      otherwise Output = 255.<br />
      - For <em>Mode</em> = <em>Truncated</em>:<br />
      if <em>Low Threshold</em> < Input < <em>High Threshold</em><br />
      then Output = Input otherwise Output = 0;<br />
      if <em>High Threshold</em> < Input < <em>Low Threshold</em><br />
      then Output = Input<br />
      otherwise Output = 255.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Low Threshold</strong><br />
        <em
          >The values smaller than the <em>Low Threshold</em> will be set to
          0.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>High Threshold</strong><br />
        <em
          >The values bigger than the <em>High Threshold</em> will be set to
          0.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em>Determines whether to saturate or truncate the values.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Improve the readability of a license plate or some text.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Identify defective pixels in an image or video.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 235–237, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Adaptive-Threshold">Adaptive Threshold</a></h3>
    <p><em>Extracts the edges with an adaptive thresholding algorithm.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Adaptive Threshold</em> tool processes the values of the input
      image by the following formula:<br />
      if (Input > T)<br />
      then Output = Input, where:<br />
      - for <em>Type</em> = <em>Mean</em>, T is the mean value of a window of
      <em>Size</em>x<em>Size</em> pixels around the processed pixel, subtracted
      by <em>Offset</em>;<br />
      - for <em>Type</em> = <em>Gaussian</em>, T is the Gaussian weighted sum of
      a window of <em>Size</em>x<em>Size</em> pixels around the current one,
      subtracted by <em>Offset</em>.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em
          >Size of a pixel neighborhood that is used to calculate the threshold
          value T for each pixel of the image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Offset</strong><br />
        <em>Constant to be subtracted from the threshold value T.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em>Thresholding type.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Sign</strong><br />
        <em>Direction of thresholding.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 235–237, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Laplace">Laplace</a></h3>
    <p><em>Extracts the edges with a Laplacian algorithm.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Laplace</em> filter calculates the Laplacian of the source image
      by summing second x- and y- derivatives calculated by using Sobel
      operator:<br />
      Output = d²Input/dx² + d²Input/dy².
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Size of the kernel used to compute the second-derivative filter.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 347–357, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Sobel">Sobel</a></h3>
    <p><em>Extracts the edges with a Sobel algorithm.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Sobel</em> filter calculates the image derivative by convolving
      the image with the appropriate Sobel kernel.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Direction</strong><br />
        <em>Main direction of the edges to be detected.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Size of the Sobel kernel.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Order</strong><br />
        <em>Derivative order.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Offset</strong><br />
        <em>Offset added to the output.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 347–357, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Scharr">Scharr</a></h3>
    <p><em>Extracts the edges with a Scharr algorithm.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Scharr</em> filter convolves the image with the following
      kernels:<br />
      - for <em>Direction</em> = <em>Horizontal</em>:<br />
      | -3 0 3|<br />
      |-10 0 10|<br />
      | -3 0 3|;<br />
      - for <em>Direction</em> = <em>Vertical</em>:<br />
      | -3 -10 3|<br />
      | 0 0 0|<br />
      | -3 -10 3|.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Direction</strong><br />
        <em>Main direction of the edges to be detected.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Offset</strong><br />
        <em>Offset added to the output.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 256–258, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Canny">Canny</a></h3>
    <p><em>Extracts the edges with a Canny algorithm.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Canny</em> filter finds the edges on the input image and marks
      them on the output image by using the Canny algorithm. The smallest value
      between <em>Threshold 1</em> and <em>Threshold 2</em> is used for edge
      linking, while the largest one is used to find the initial segments of
      strong edges.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Size of the kernel used for filtering.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Threshold 1</strong><br />
        <em>First edge threshold.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Threshold 2</strong><br />
        <em>Second edge threshold.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        John Canny, “A Computational Approach to Edge Detection”, in IEEE
        Transactions on Pattern Analysis and Machine Intelligence, Vol. 8, No.
        6, pp. 679–698, November 1986.
        <a href="http://dx.doi.org/10.1109/TPAMI.1986.4767851" target="_blank"
          >http://dx.doi.org/10.1109/TPAMI.1986.4767851</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Linear-Filter">Linear Filter</a></h3>
    <p><em>Filters the image with a user-defined kernel.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Linear Filter</em> performs the convolution of the input image
      with a given matrix. Each value of the matrix is multiplied by an optional
      rational scaling value.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Matrix</strong><br />
        <em>Matrix containing the user-defined kernel.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Scale</strong><br />
        <em>The value that multiplies all the elements in the matrix.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        The Ghostreader: Learn How to Read Latent Writings on White Paper Using
        بـستا and Some Intuition!:
        <a
          href="https://blog.ampedsoftware.com/2019/09/10/the-ghostreader-learn-how-to-read-latent-writings-on-white-paper-using-amped-five-and-some-intuition/"
          target="_blank"
          >https://blog.ampedsoftware.com/2019/09/10/the-ghostreader-learn-how-to-read-latent-writings-on-white-paper-using-amped-five-and-some-intuition/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Bilinear-Filter">Bilinear Filter</a></h3>
    <p>
      <em
        >Filters the image with two user-defined kernels and combines the
        results.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Bilinear Filter</em> performs the convolution of the input image
      with two given matrices. The results are combined by taking the norm,
      minimum or maximum. The output is multiplied by an optional rational
      scaling value.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Matrix 1</strong><br />
        <em>Matrix containing the first user-defined kernel.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Matrix 2</strong><br />
        <em>Matrix containing the second user-defined kernel.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Scale</strong><br />
        <em>The value that multiplies all the output pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Combination method</strong><br />
        <em>Method used to combine the outputs of the two linear filters.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Channel-Mixer">Channel Mixer</a></h3>
    <p>
      <em
        >Mixes the ratio of color in every channel as a linear combination of
        the input image channels.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Channel Mixer</em> allows to balance the proportion of color in every
      channel.<br />
      The value of each RGB component of every pixel in the output image is
      calculated weighting the value of RGB components of the same pixel in the
      input image accordingly to the parameters value specified for every
      channel, or for <em>Value</em> if setting <em>Mode</em> to
      <em>Grayscale</em>. The result is then multiplied by the
      <em>Constant</em> specified for the channel.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em
          >Color mode: Value settings work only in Grayscale mode; Red, Green
          and Blue settings work only in Color mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Value Red</strong><br />
        <em
          >Percentage of the Red value of the input image which will be mixed in
          Value of the output pixel for Grayscale mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Value Green</strong><br />
        <em
          >Percentage of the Green value of the input image which will be mixed
          in Value of the output pixel for Grayscale mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Value Blue</strong><br />
        <em
          >Percentage of the Blue value of the input image which will be mixed
          in Value of the output pixel for Grayscale mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Value Constant</strong><br />
        <em
          >Percentage of the combination of colors which will be added to the
          overall value.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Red Red</strong><br />
        <em
          >Percentage of the Red value of the input image which will be mixed in
          the Red value of the output pixel for Color mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Red Green</strong><br />
        <em
          >Percentage of the Green value of the input image which will be mixed
          in the Red value of the output pixel for Color mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Red Blue</strong><br />
        <em
          >Percentage of the Blue value of the input image which will be mixed
          in the Red value of the output pixel for Color mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Red Constant</strong><br />
        <em
          >Percentage of the combination of colors which will be added to the
          overall red value.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Green Red</strong><br />
        <em
          >Percentage of the Red value of the input image which will be mixed in
          the Green value of the output pixel for Color mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Green Green</strong><br />
        <em
          >Percentage of the Green value of the input image which will be mixed
          in the Green value of the output pixel for Color mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Green Blue</strong><br />
        <em
          >Percentage of the Blue value of the input image which will be mixed
          in the Green value of the output pixel for Color mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Green Constant</strong><br />
        <em
          >Percentage of the combination of colors which will be added to the
          overall green value.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Blue Red</strong><br />
        <em
          >Percentage of the Red value of the input image which will be mixed in
          the Blue value of the output pixel for Color mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Blue Green</strong><br />
        <em
          >Percentage of the Green value of the input image which will be mixed
          in the Blue value of the output pixel for Color mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Blue Blue</strong><br />
        <em
          >Percentage of the Blue value of the input image which will be mixed
          in the Blue value of the output pixel for Color mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Blue Constant</strong><br />
        <em
          >Percentage of the combination of colors which will be added to the
          overall blue value.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Separate inks of different colors from a document.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 234–241, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        Channel Mixer in بـستا:
        <a
          href="https://blog.ampedsoftware.com/2012/08/24/channel-mixer-in-amped-five-2/"
          target="_blank"
          >https://blog.ampedsoftware.com/2012/08/24/channel-mixer-in-amped-five-2/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Color-Deconvolution">Color Deconvolution</a></h3>
    <p>
      <em>Maximizes the differences between specific colors in the image.</em>
    </p>
    <h4>Details</h4>
    <p>
      <em>Color Deconvolution</em> allows to separate or extract different
      colors in an image, changing the standard RGB color space to a new one
      which maximizes the differences between user selected colors.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Desired Color Point</strong><br />
        <em
          >Coordinates of the point used to sample the desired color to
          extract.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Undesired Color Point</strong><br />
        <em
          >Coordinates of the point used to sample the first unwanted color to
          remove.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Undesired Color Point 2</strong><br />
        <em
          >Coordinates of the point used to sample the second unwanted color to
          remove.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Background Color Point</strong><br />
        <em>Coordinates of the point used to sample the background color.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Size of the window to average to calculate color values.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Color Mode</strong><br />
        <em>The operation performed by the filter.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Select, using the <em>Point</em> tool and the appropriate tab in the
      filter settings, a <em>Desired Color</em>, one or two
      <em>Undesired Colors</em> and a <em>Background Color</em>. The filter will
      generate and apply an affine linear transformation to the image's RGB
      channels that transforms the undesired color(s) into the background color
      and leaves the other user-selected colors unchanged. The transformation is
      determined by the <em>Color Mode</em> setting. <em>Legacy</em> is the
      original method described in (Berger et al., 2006) and removes only the
      first undesired color. Also <em>Min. Color Shift</em> removes only the
      first undesired color but uses a different method that minimizes the mean
      squared difference between the input and output images. This technique is
      known as the Monge-Kantorovitch optimal transportation problem. Finally,
      <em>Remove First and Second Color</em> removes both undesired colors.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Separate inks of different colors from graffiti on the wall.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Charles E. H. Berger, Jan A. de Koeijer, Wendy Glas and Henk T.
        Madhuizen, “Color separation in forensic image processing”, in Journal
        of Forensic Sciences, Vol. 51, No. 1, pp. 100–102, January 2006.
        <a
          href="http://dx.doi.org/10.1111/j.1556-4029.2005.00020.x"
          target="_blank"
          >http://dx.doi.org/10.1111/j.1556-4029.2005.00020.x</a
        >
      </li>
      <li>
        F. Pitié and A. Kokaram, “The Linear Monge-Kantorovitch Linear Colour
        Mapping for Example-Based Colour Transfer”, in Proceedings of the 4th
        European Conference on Visual Media Production (IETCVMP 2007), pp. 1–9,
        2007.
        <a href="http://dx.doi.org/10.1049/cp:20070055" target="_blank"
          >http://dx.doi.org/10.1049/cp:20070055</a
        >
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        Color Deconvolution in بـستا:
        <a
          href="https://blog.ampedsoftware.com/2012/12/19/color-deconvolution-in-amped-five/"
          target="_blank"
          >https://blog.ampedsoftware.com/2012/12/19/color-deconvolution-in-amped-five/</a
        >
      </li>
      <li>
        Read Beneath the Lines! Learn How بـستا’s Color Deconvolution Filter
        Helps You Take Out Relevant Elements from Color-Mixed Images:
        <a
          href="https://blog.ampedsoftware.com/2019/08/20/read-beneath-the-lines-learn-how-amped-fives-color-deconvolution-filter-helps-you-take-out-relevant-elements-from-color-mixed-images/"
          target="_blank"
          >https://blog.ampedsoftware.com/2019/08/20/read-beneath-the-lines-learn-how-amped-fives-color-deconvolution-filter-helps-you-take-out-relevant-elements-from-color-mixed-images/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Component-Separation">Component Separation</a></h3>
    <p>
      <em
        >Separates signals due to different informative components in the
        image.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The filter <em>Component Separation</em> uses the Fast ICA (Independent
      Component Analysis) algorithm to separate the images into the most
      independent components. The algorithm assumes that the three RGB
      components of the signal represent three different linear combinations of
      three independent input signals. After the processing the three estimated
      input signals are mapped on the three RGB channels of the output image.
      This filter does not process grayscale images.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Channel</strong><br />
        <em>Channels(s) to extract.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Separate a latent fingerprint from the background.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Separate a print stamp from a post stamp.<a href="" target="_blank"></a>
      </li>
      <li>
        Separate a reflection from what's behind it.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Aapo Hyvärinen and Erkki Oja, “Independent Component Analysis:
        Algorithms and Applications”, in Neural Networks, Vol. 13, No. 4–5, pp.
        411–430, June 2000.
        <a
          href="http://dx.doi.org/10.1016/S0893-6080(00)00026-5"
          target="_blank"
          >http://dx.doi.org/10.1016/S0893-6080(00)00026-5</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Fourier">Fourier</a></h3>
    <p>
      <em
        >Removes periodic noise, background and interferences in the Fourier
        domain. Useful for latent fingerprints, capture artifacts and
        electromagnetic interferences in videos.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Fourier</em> tool filters an image in the frequency domain, which
      allows to easily remove parts of the spectrum where interferences and/or
      periodic noise are located. This is done by setting to zero selected areas
      of the spectrum and then calculating its inverse Fourier transform with
      the inverse DFT algorithm. Both manual and automatic selection tools are
      available.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Automatic Selection</strong><br />
        <em
          >Automatically select the peaks in the FFT (can be refined
          manually).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output</strong><br />
        <em>Domain of the output image.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Smoothing</strong><br />
        <em>Smoothing.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selections to Remove</strong><br />
        <em>Regions of the spectrum to be removed.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selections to Keep</strong><br />
        <em>Regions of the spectrum to be preserved.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Set <em>Output</em> to <em>Frequency Spectrum (FFT)</em>, which shows the
      image FFT (Fast Fourier Transform), or to <em>Side by Side</em>, which
      shows the FFT together with the processed image. In these modes, you can
      set to zero specific portions of the FFT, which correspond to the
      interferences. Three selection methods are available:<br />
      - Select with the <em>Select</em> tool the areas you wish to set to zero
      and click on <em>Add</em> in the <em>Selections to Remove</em> control. If
      you need to undo a selection, select it on the list and click on the
      button <em>Delete</em>.<br />
      - Select with the <em>Select</em> tool the areas you wish to keep and then
      click on <em>Add</em> in the <em>Selections to Keep</em> control. This
      tool, combined with the previous one, can be used to define selections
      with complex shapes or holes.<br />
      - Click on the <em>Automatic Selection</em> control to automatically
      detect the peaks of the FFT, which typically correspond to strong periodic
      patterns or interferences. If necessary, use the
      <em>Selections to Remove</em> or <em>Selections to Keep</em> controls to
      fine tune the selection.<br />
      - The filter may, in some cases, introduce ringing artifacts near sharp
      edges in the image. If this occurs, use the <em>Smoothing</em> slider to
      reduce the artifacts. This, however, also reduces the effect of the
      filter.<br />
      To check how the filter affects the output image, set <em>Output</em> to
      <em>Image (IFFT)</em> or <em>Side by Side</em>, which show the inverse FFT
      of the filtered spectrum.<br />
      It is possible to show the deleted data by setting <em>Output</em> to
      <em>Image Complement (IFFT)</em>.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Separate a latent fingerprint from the background.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Remove periodic interference from a camera.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Remove Moiré artifacts from a photo of a screen.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Remove artifacts from a scanned photo.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 145–150, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        Science at Your Service: Learn How to Remove Periodic Noise With بـستا’s
        Fourier Filter:
        <a
          href="https://blog.ampedsoftware.com/2019/12/17/science-at-your-service-learn-how-to-remove-periodic-noise-with-amped-fives-fourier-filter/"
          target="_blank"
          >https://blog.ampedsoftware.com/2019/12/17/science-at-your-service-learn-how-to-remove-periodic-noise-with-amped-fives-fourier-filter/</a
        >
      </li>
    </ul>
    <hr />
    <h2><a name="Verify">Verify</a></h2>
    <p><em>Tools to authenticate digital images.</em></p>
    <hr />
    <h3><a name="File-Info">File Info</a></h3>
    <p><em>Saves file information and EXIF metadata on the report.</em></p>
    <h4>Details</h4>
    <p></p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Info</strong><br />
        <em>Metadata information saved with the file.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Verify the date when a picture has been taken.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Verify if the images have been saved with Photoshop.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Display the camera used for taking the photo.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Hash-Code">Hash Code</a></h3>
    <p>
      <em
        >Calculates the input file hash code to check data integrity when
        loading the project. Supports several hashing algorithms.</em
      >
    </p>
    <h4>Details</h4>
    <p></p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em>Hash code algorithm to use.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Hash Codes</strong><br />
        <em>List of calculated hash codes.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Univoquely identify the input file to process.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Verify that the input and output files have not been changed.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Verify that the content of two images is the same.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        In a Flash, with the Hash! Learn How to Quickly Spot Identical Frames in
        بـستا:
        <a
          href="https://blog.ampedsoftware.com/2019/07/30/in-a-flash-with-the-hash-learn-how-to-quickly-spot-identical-frames-in-amped-five/"
          target="_blank"
          >https://blog.ampedsoftware.com/2019/07/30/in-a-flash-with-the-hash-learn-how-to-quickly-spot-identical-frames-in-amped-five/</a
        >
      </li>
      <li>
        VeriFIVE your files (aka "How to hash-check files in your بـستا
        project"):
        <a
          href="https://blog.ampedsoftware.com/2019/03/12/verifive-your-files-aka-how-to-hash-check-files-in-your-amped-five-project/"
          target="_blank"
          >https://blog.ampedsoftware.com/2019/03/12/verifive-your-files-aka-how-to-hash-check-files-in-your-amped-five-project/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Macroblocks">Macroblocks</a></h3>
    <p>
      <em
        >Visualizes the macroblock type and motion vectors from a MPEG based
        video.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Macroblocks</em> filter will write a new video file which displays
      the MPEG macroblock type and its motion vectors, depending on the
      configured settings. This analysis allows to evaluate the reliability of
      information in the different parts of the image.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>File</strong><br />
        <em>Path of the file to save.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Format</strong><br />
        <em>Container and codec used to write the video file.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Macroblock Type</strong><br />
        <em
          >If enabled, overlays different colors on macroblocks according to
          their type.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show P Forward Motion Vectors</strong><br />
        <em
          >If enabled, overlays arrows that show the forward predicted motion
          vectors of P frames.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show B Forward Motion Vectors</strong><br />
        <em
          >If enabled, overlays arrows that show the forward predicted motion
          vectors of B frames.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show B Backward Motion Vectors</strong><br />
        <em
          >If enabled, overlays arrows that show the backward predicted motion
          vectors of B frames.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Gray blocks have been copied from another frame. Green blocks have changes
      in the luminance or location and are referenced to the previous frame.
      Blue blocks have changes in the luminance or location and are referenced
      to the next frame. Red blocks are newly encoded data from the current
      frame and thus are more reliable. There are a number of possible colors
      and types. For more information check:
      https://trac.ffmpeg.org/wiki/Debug/MacroblocksAndMotionVectors.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Identify which data in a frame is of better quality and more reliable on
        the original stream.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        Understanding the Macroblocks Filter:
        <a
          href="https://blog.ampedsoftware.com/2016/03/08/understanding-the-macroblocks-filter/"
          target="_blank"
          >https://blog.ampedsoftware.com/2016/03/08/understanding-the-macroblocks-filter/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Block-Difference">Block Difference</a></h3>
    <p>
      <em
        >Compute the difference between the current and previous frames of a
        video and hide the blocks with an average difference below a specified
        threshold.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Block Difference</em> tool computes the difference between the
      current and previous frames of a video and takes the average over blocks.
      The blocks with an average difference below an user-specified threshold
      are gradually blackened out. Both absolute and relative difference modes
      are supported.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Difference Mode</strong><br />
        <em>Choose between an absolute or relative difference.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Block Size</strong><br />
        <em>Size of the blocks used to average the difference.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Threshold</strong><br />
        <em
          >The blocks with an average difference below this value are gradually
          blackened out.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The <em>Block Difference</em> tool can be used to focus the observer's
      attention onto the parts of the video that change over time. The
      <em>Absolute</em> mode can be used if the frame has a uniform
      illumination; the <em>Relative</em> mode, instead, may be preferable if
      the frame contains both illuminated and dark portions.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Identify which data in a frame is of better quality and more reliable on
        a converted stream.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h2><a name="Measure">Measure</a></h2>
    <p><em>Extracts real-world measurements from images.</em></p>
    <hr />
    <h3><a name="Measure-1d">Measure 1d</a></h3>
    <p>
      <em
        >Takes a measurement on the planar image. Reference and unknown measure
        must be on the same plane and the plane must be parallel to the image
        plane.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Measure 1d</em> tool computes a distance in the real world from
      the image. The real-world distance between any couple of points in the
      image is computed by calculating the ratio between their pixel distance
      and the pixel density, where the pixel density is obtained as the ratio
      between the pixel length and the real-world length of the reference
      segment.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Reference Line</strong><br />
        <em
          >The pixel coordinates of the line whose dimension is known by the
          user.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Reference Length</strong><br />
        <em
          >The real-world distance (m, cm, mm, yd, ft, in...) between the
          endpoints of the reference line.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Unit of Measurement</strong><br />
        <em>The measurement unit used in the process.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Decimal Places</strong><br />
        <em>The number of decimal digits in the computed measurement.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Line</strong><br />
        <em>The pixel coordinates of the target of the measurement.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Length</strong><br />
        <em
          >The real-world value (m, cm, mm, yd, ft, in...) of the output of the
          measurement.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Reference Line</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Reference Measure</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Output Line</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Output Measure</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      In the <em>Reference</em> tab, select two points on the image that will
      define the known distance. This segment is used as reference. In the
      <em>Measure</em> tab, mark the two endpoints of a segment you wish to
      measure. The <em>Measure 1d</em> method does not rely on any geometric
      information from the scene, so the filter has to be used with images which
      are not affected by perspective and lens distortions. For further details,
      please browse the <em>Tutorial</em> section of the user manual.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>Measure some objects on a plane.<a href="" target="_blank"></a></li>
      <li>
        Measure fingerprints, footprints or other evidence with a ruler.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Measure-2d">Measure 2d</a></h3>
    <p>
      <em
        >Takes a measurement on planar image after perspective correction.
        Reference and unknown measure must be on the same plane.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Measure 2d</em> tool computes a specific measurement distance in a
      rectified image. Given an image of a planar surface, points on the image
      plane can be mapped into corresponding points in the rectified plane by
      means of a projective transformation called homography. Points in one
      plane are mapped into the corresponding points in the other plane as
      follows:<br />
      X = Hx<br />
      where x is an image point, X is the corresponding point on the world plane
      and H is the 3x3 matrix representing the homography transformation.<br />
      Once the homography matrix H is known (or has been computed), any image
      point can be mapped into the corresponding location on the rectified
      planar surface and the distance between two points x1 and x2 on the image
      plane can be obtained by computing the Euclidean distance d(X1,X2) between
      the corresponding points X1 and X2 on the rectified plane. The homography
      is computed from a set of at least four points by the
      <em>Perspective Correction</em> filter, that must be applied before
      <em>Measure 2d</em>.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>X-axis Reference Line</strong><br />
        <em
          >The pixel coordinates of the horizontal line whose dimension is known
          by the user.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>X-axis Reference Length</strong><br />
        <em
          >The real-world distance (m, cm, mm, yd, ft, in...) between the
          endpoints of the x-axis reference line.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Unit of Measurement</strong><br />
        <em>The measurement unit used in the process.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Decimal Places</strong><br />
        <em>The number of decimal digits in the computed measurement.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Y-axis Reference Line</strong><br />
        <em
          >The pixel coordinates of the vertical line whose dimension is known
          by the user.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Y-axis Reference Length</strong><br />
        <em
          >The real-world distance (m, cm, mm, yd, ft, in...) between the
          endpoints of the y-axis reference line.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Line</strong><br />
        <em>The pixel coordinates of the target of the measurement.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Length</strong><br />
        <em
          >The real-world value (m, cm, mm, yd, ft, in...) of the output of the
          measurement.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show X Line</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show X Measure</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Y Line</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Y Measure</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Output Line</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Output Measure</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      First, the user selects two segments: one in the horizontal (x-axis)
      direction and the other one in the vertical (y-axis) direction. The
      lengths of these segments are known and used as reference. Then, the user
      marks the two points that will define the segment to measure. The
      <em>Measure 2d</em> filter has to be used once the image has been
      corrected for perspective distortion, i.e. the homography is estimated by
      applying the <em>Perspective Correction</em> filter and the image of
      slanted planar surfaces is rectified into front-on view. For further
      details, please browse the <em>Tutorial</em> section of the user manual.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>Measure traces of an accident.<a href="" target="_blank"></a></li>
      <li>
        Estimate the kind of car from a very low quality video.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Measure-3d">Measure 3d</a></h3>
    <p>
      <em
        >Takes a measurement on the image with a reconstruction model of the
        perspective. Supports error calculation and multiple measures.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Measure 3d</em> tool computes real-world distances directly on the
      image. The measure estimation algorithm is based on the Single View
      Metrology (SVM) approach described by Criminisi, Reid and Zisserman in
      <em>Single View Metrology</em>. The SVM is based on the fact that image
      lines which are parallel in the real-world join in a point in the image,
      named vanishing point, due to the perspective. The vanishing points are
      computed by marking on the image two or more lines, parallel in the real
      world, for each direction (x, y, z). The scene perspective can be
      reconstructed from the vanishing points by transforming the geometric
      information into a system of linear constraints on the coordinates of the
      3D points and using the known distance as a further constraint. As result,
      3D measurements along one of the selected axes may be computed from a
      single perspective view of a scene given only this minimal geometric
      information determined from the image. Since the data input by the user
      can be imprecise, the output measurements are uncertain. In order to
      estimate how the uncertainty propagates from the input to the output of
      the processing chain, the filter computes the error variance using
      Gaussian quadrature and provides a confidence interval equal to +/- 3
      standard deviations.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>X-axis Lines</strong><br />
        <em
          >The set of the pixel coordinates of the lines which are defined by
          the user in the x direction of the scene.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Y-axis Lines</strong><br />
        <em
          >The set of the pixel coordinates of the lines which are defined by
          the user in the y direction of the scene.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Z-axis Lines</strong><br />
        <em
          >The set of the pixel coordinates of the lines which are defined by
          the user in the z direction of the scene.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Reference Axis Direction</strong><br />
        <em
          >The X/Y/Z direction along which a metric information is known (some
          reference distances are known).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Reference Line</strong><br />
        <em
          >The pixel coordinates of the image segment in the X/Y/Z direction
          which is used as reference.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Reference Length</strong><br />
        <em
          >The real-world distance (m, cm, mm, yd, ft, in...) between the
          endpoints of the reference line.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Unit of Measurement</strong><br />
        <em>The measurement unit used in the process.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Decimal Places</strong><br />
        <em>The number of decimal digits in the computed measurement.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Camera Position</strong><br />
        <em
          >Estimated distance between the center of the objective and the ground
          base plane.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Correct Direction</strong><br />
        <em
          >Swap points 1 and 2 of reference and measurement if the active axis
          is z and point 1 is above point 2.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Line</strong><br />
        <em>The pixel coordinates of the target of the measurement.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Length</strong><br />
        <em
          >The real-world value (m, cm, mm, yd, ft, in...) of the output of the
          measurement.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Error</strong><br />
        <em
          >The uncertainty (m, cm, mm, yd, ft, in...) associated with the output
          measurement.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Experimental Error</strong><br />
        <em
          >The error obtained by measuring a known object (e.g. a measuring rod)
          in the scene.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Range</strong><br />
        <em>The Output Length +/- the greatest of the two errors above.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Line 2</strong><br />
        <em>The pixel coordinates of the target of the second measurement.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Length 2</strong><br />
        <em
          >The real-world value (m, cm, mm, yd, ft, in...) of the output of the
          second measurement.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Error 2</strong><br />
        <em
          >The uncertainty (m, cm, mm, yd, ft, in...) associated with the output
          of the second measurement.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Range 2</strong><br />
        <em>The Output Length 2 +/- the greatest of the two errors above.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Difference</strong><br />
        <em>The difference between the first and the second measurement.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Helper Lines</strong><br />
        <em>Unconstrained lines that may help you to understand the scene.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Helper Lines Alignment</strong><br />
        <em
          >Optionally align the current line to one of the computed vanishing
          points.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show X Lines</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Y Lines</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Z Lines</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Reference Line</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Reference Measure</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Output Line</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Output Measure</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Helper Lines</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Show Horizon</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      First, two or more lines for each direction of 3D space are selected, then
      the reference distance in a x/y/z direction is defined and finally the
      measurement is taken from image in same direction of the reference line.
      It's suggested to take more than 2 lines for every direction, if they can
      be reliably set. The orientation of the 3 sets of lines doesn't need to be
      orthogonal.<br />
      The SVM-based algorithms have been designed to work in an uncalibrated
      framework (i.e. no need for the camera pose or internal parameters -e.g.
      focal length- to be known or computed). On the other hand, scene
      constraints such as the parallelism of structures are exploited, thus
      making these algorithms especially suitable for scenes containing man-made
      structures such as architectural elements and geometric patterns. This
      means that the <em>Measure 3d</em> filter has to be used in images with a
      structured scene, i.e. reliable and well defined geometric structures of
      the scene need to be seen in the image for reconstructing the perspective
      of the scene. For further details, please browse the
      <em>Tutorial</em> section of the user manual.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>Measure the height of a suspect.<a href="" target="_blank"></a></li>
      <li>Measure the height of a building.<a href="" target="_blank"></a></li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        A. Criminisi, I. Reid, and A. Zisserman, “Single View Metrology”, in
        International Journal of Computer Vision, Vol. 40, No. 2, pp. 123–148,
        November 2000.
        <a href="http://dx.doi.org/10.1023/A:1026598000963" target="_blank"
          >http://dx.doi.org/10.1023/A:1026598000963</a
        >
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        Calculate camera position from a picture or video:
        <a
          href="https://blog.ampedsoftware.com/2013/09/25/calculate-camera-position-from-a-picture-or-video/"
          target="_blank"
          >https://blog.ampedsoftware.com/2013/09/25/calculate-camera-position-from-a-picture-or-video/</a
        >
      </li>
      <li>
        On the Fly! Learn How to Use بـستا’s Measure 3D Filter to Measure
        Objects That Are Not on the Ground:
        <a
          href="http://blog.ampedsoftware.com/2019/11/12/on-the-fly-learn-how-to-use-amped-fives-measure-3d-filter-to-measure-objects-that-are-not-on-the-ground/"
          target="_blank"
          >http://blog.ampedsoftware.com/2019/11/12/on-the-fly-learn-how-to-use-amped-fives-measure-3d-filter-to-measure-objects-that-are-not-on-the-ground/</a
        >
      </li>
      <li>
        The Beginner’s Guide to Suspect Height Calculation from CCTV:
        <a
          href="https://blog.ampedsoftware.com/2017/08/17/the-beginners-guide-to-suspect-height-calculation-from-cctv/"
          target="_blank"
          >https://blog.ampedsoftware.com/2017/08/17/the-beginners-guide-to-suspect-height-calculation-from-cctv/</a
        >
      </li>
    </ul>
    <hr />
    <h2><a name="Sharpen">Sharpen</a></h2>
    <p><em>Enhances image details.</em></p>
    <hr />
    <h3><a name="Laplacian-Sharpening">Laplacian Sharpening</a></h3>
    <p><em>Sharpens the image using a Laplacian filter algorithm.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Laplacian Sharpening</em> filter convolves the image with a 3x3
      Laplacian kernel and then adds the resulting high-passed image onto the
      original image. More specifically, the amount of high-passed information
      added to original image is proportional to the <em>Strength</em> of
      sharpening. The result of this sharpening operator is to increase the
      contrast between each pixel and its neighbors. The Laplacian-based unsharp
      masking is sensible to noise due to the nature of the Laplacian operator.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Strength</strong><br />
        <em
          >Strength of the sharpening effect; larger values provide increasing
          amounts of sharpening.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em>Type of adjustment to be done.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>Sharpen a license plate.<a href="" target="_blank"></a></li>
      <li>Sharpen a face.<a href="" target="_blank"></a></li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 249–250, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Unsharp-Masking">Unsharp Masking</a></h3>
    <p><em>Sharpens the image using an unsharp masking filter.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Unsharp Masking</em> filter is implemented as a window-based
      operator, i.e. it relies on a convolution kernel to perform spatial
      filtering. The original image is first convolved with a <em>Radius</em> x
      <em>Radius</em> Gaussian kernel to produce its smoothed version, i.e. a
      low-passed image. The resulting image is then pixel subtracted from the
      original image in order to produce a description of image edges, i.e. a
      high-passed image. Only the pixel differences (edges) greater than certain
      <em>Threshold</em> values are retained, so that sharpening of small image
      details can be suppressed. In order to increase the sharpness of the
      original image, a percentage (proportional to <em>Strength</em>) of the
      thresholded high-passed image is added back onto the original image.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Strength</strong><br />
        <em
          >Intensity of the sharpening effect: larger values provide increasing
          amounts of sharpening.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em
          >Length, in pixels, of the side of the square filter window. High
          resolution images allow a higher size.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Threshold</strong><br />
        <em
          >The minimum difference in pixel values that indicates an edge where
          sharpen must be applied. So you can protect areas of smooth tonal
          transition from sharpening, and avoid creation of blemishes in the
          facial, sky or water surface.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em>Type of adjustment to be done.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>Sharpen a license plate.<a href="" target="_blank"></a></li>
      <li>Sharpen a face.<a href="" target="_blank"></a></li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 249–250, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h2><a name="Denoise">Denoise</a></h2>
    <p><em>Reduces the image noise.</em></p>
    <hr />
    <h3><a name="Averaging-Filter">Averaging Filter</a></h3>
    <p><em>Smooths the image with an averaging filter.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Averaging Filter</em> performs a spatial linear filtering of the
      image. The pixel value of the output image is computed by averaging the
      values of the input image in the neighborhood of the corresponding input
      pixel.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Size of the filter kernel in pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The <em>Averaging Filter</em> is a linear low-pass filter that is often
      used to reduce the intensity variation between adjacent pixels in the
      image. It is useful for removing grain noise from a scanned
      image/photograph, but it is not effective for impulsive noise
      (salt-and-pepper). The main problem of the averaging filter is that edges
      and details in the processed image are blurred. The value of the parameter
      <em>Aperture</em> should be chosen to minimize the blurring (smoothing)
      effect. A 3x3 square kernel is commonly used. Note that larger windows
      (e.g. 5x5, 7x7, ...) will produce a smoother image after averaging.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Denoise an image taken in low light conditions.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Denoise a video after making it brighter.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 244–245, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Gaussian-Filter">Gaussian Filter</a></h3>
    <p><em>Smooths the image using a Gaussian filter algorithm.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Gaussian Filter</em> applies a Gaussian filter to the image. The
      value of the output pixel is computed as a weighted average of its
      neighbors, in which the weights decrease with distance from the
      neighborhood center.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Size of the Gaussian kernel in pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Sigma</strong><br />
        <em>Standard deviation of the Gaussian distribution.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em>Optionally compute one of the parameters from the other one.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      <em>Gaussian Filter</em> is a low-pass filter used to blur images reducing
      noise and detail. It preserves edges better than a similarly sized
      averaging filter. The amount of smoothing is determined by the value of
      the parameter <em>Sigma</em>: larger values produce smoother images with
      fewer details.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Denoise an image taken in low light conditions.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Denoise a video after making it brighter.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 256–258, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Wiener-Filter">Wiener Filter</a></h3>
    <p><em>Smooths the image with a Wiener filter.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Wiener Filter</em> performs an adaptive filtering of an image
      degraded by additive noise. For each pixel of the input image, the local
      mean and variance from a square neighborhood of size <em>Aperture</em> are
      estimated. Then, the value of the output pixel is obtained combining the
      corresponding input pixel value, the estimated local statistics and the
      noise variance set by parameter <em>Noise</em>. The
      <em>Wiener Filter</em> can tailor itself to the local image statistics.
      Where the variance is large, the filter performs little smoothing. Where
      the variance is small, the filter performs more smoothing.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Size of the filter kernel in pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Noise</strong><br />
        <em
          >Amount of noise to be reduced. If zero, noise level is automatically
          computed.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The <em>Wiener Filter</em> is an adaptive low-pass filter used to remove
      noise from images. It works best when the noise is white additive noise,
      such as Gaussian noise. If the parameter <em>Noise</em> is zero, the
      Wiener routine also estimates the noise level before doing the filtering.
      The <em>Wiener Filter</em> is more selective than a comparable linear
      filter in preserving edges and other high frequency parts of an image. The
      value of the parameter <em>Aperture</em> should be a trade-off between
      noise removing and detail preserving: larger values can remove noise more
      effectively, but also blur the details/edges.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Denoise an image taken in low light conditions.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Denoise a video after making it brighter.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Jae S. Lim, “Two-Dimensional Signal and Image Processing”, Prentice
        Hall, Englewood Cliffs, NJ, 1990. ISBN: 0-13-935322-4.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Bilateral-Filter">Bilateral Filter</a></h3>
    <p><em>Smooths the image with a bilateral Gaussian filter.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Bilateral Filter</em> uses a non-linear combination of similar and
      nearby pixels in order to smooth the image. The value of the input pixel
      is replaced with a weighted sum of its neighbors considering both their
      geometric closeness and photometric similarities. The bilateral filter is
      controlled by three parameters: <em>Aperture</em>,
      <em>Space Sigma</em> and <em>Range Sigma</em>. They affect the size and
      contrast of the structures to preserve. <em>Aperture</em> is the diameter
      of the pixel neighborhood that is used for filtering.
      <em>Space Sigma</em> defines spatial closeness: larger values mean that
      farther pixels in the neighborhood will influence each other as long as
      their intensities or colors are similar enough.
      <em>Range Sigma</em> defines photometric similarity: larger values mean
      that farther gray-levels or colors within the pixel neighborhood will be
      mixed together, resulting in larger areas of similar pixel values.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Size of the Gaussian bilateral kernel in pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Space Sigma</strong><br />
        <em
          >Standard deviation of the Gaussian distribution for pixel
          positions.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Range Sigma</strong><br />
        <em
          >Standard deviation of the Gaussian distribution for differences of
          pixel values.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The <em>Bilateral Filter</em> is a non-iterative, non-linear scheme for
      edge-preserving smoothing. Usually, in denoising applications, it is
      preferred to Gaussian and median filters because it produces a much
      cleaner image without blurring the edges. The three parameters of the
      filter control the amount of smoothing. When the <em>Range Sigma</em> is
      large the filter behaves like a low-pass Gaussian: noise as well as sharp
      edges are filtered away. Conversely, when it is small, the filter removes
      most texture, noise, and fine details but contours are preserved better.
      Increasing both <em>Aperture</em> and <em>Space Sigma</em> will smooth
      large structures in the image so that the blurring effect of the filter
      will be stronger. When the <em>Aperture</em> is large the processing speed
      decreases, so it is recommended to limit the kernel size of filter. In
      contrast to standard Gaussian spatial smoothing, bilateral filtering
      produces no phantom colors along edges in color images, and reduces
      phantom colors where they appear in the original image.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Denoise an image taken in low light conditions.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Denoise a video after making it brighter.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        C. Tomasi and R. Manduchi, “Bilateral Filtering for Gray and Color
        Images”, in Proceedings of the IEEE International Conference on Computer
        Vision, Bombay, India, pp. 839–846, 1998.
        <a href="http://dx.doi.org/10.1109/ICCV.1998.710815" target="_blank"
          >http://dx.doi.org/10.1109/ICCV.1998.710815</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Median-Filter">Median Filter</a></h3>
    <p>
      <em
        >Reduces the impulsive noise by applying a Median filter algorithm.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Median Filter</em> replaces each pixel by the median or "middle"
      pixel value in a neighborhood around the processed pixel. The size and the
      shape of the neighborhood (kernel) are determined by the value of the
      parameters <em>Aperture</em> and <em>Type</em>, respectively. The filter
      supports the following kernels: <em>Square</em> with size defined by the
      user, <em>Horizontal</em> (1x3 or 1x5 pixels), <em>Vertical</em> (3x1 or
      5x1 pixels), <em>Cross</em> and <em>Color</em> (3x3 or 5x5 pixels). To
      ensure valid operation when image boundary pixels are processed,
      additional border pixels are defined using a proper function.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Size of the filter kernel in pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em>Shape of the filter kernel.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The <em>Median Filter</em> is a non-linear low-pass filter that removes
      intensity spikes and can be used to achieve noise reduction. It is useful
      in reducing impulse (salt-and-pepper) noise.<br />
      A median filter is able to reduce the noise without causing the typical
      blurring effect of linear low-pass filters such as the
      <em>Averaging Filter</em> and the <em>Gaussian Filter</em>. This makes
      median filtering useful for both visual examination and measurement. The
      shape of the mask has to be carefully chosen before applying the filter.
      Its choice depends on the target of the processing.<br />
      A <em>Cross</em> filter does not excessively smooth image details compared
      to the <em>Square</em> filter, and typically provides a higher quality
      output. Similarly, <em>Horizontal</em> and <em>Vertical</em> kernels do
      not reduce details respectively along vertical and horizontal direction,
      while a <em>Square</em> mask will produce a loss of detail in all
      directions. These directional kernels can be used to preserve line
      structures in the image. A square kernel can erode the corners of
      rectangular objects, while a cross mask will be used for preserving them.
      When applied to a color image, the previously described median filtering
      kernels process color planes of an image separately, and as a result any
      correlation between color components is lost.<br />
      If you want to preserve this information, select <em>Color</em> in the
      <em>Mode</em> parameter. The value of the parameter <em>Size</em> should
      be a compromise between noise removing and detail preserving: larger
      values can remove noise more effectively, but also blur the edges.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Denoise an image with impulsive noise.<a href="" target="_blank"></a>
      </li>
      <li>Correct scratches in an old VHS.<a href="" target="_blank"></a></li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 246–249, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Deblocking">Deblocking</a></h3>
    <p>
      <em
        >Reduces block artifacts from lossy compression, such as that of JPEG or
        most video formats.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Deblocking</em> applies a rational filter in order to remove
      artifacts, caused by lossy compression, such as those which are usually
      present in heavily compressed JPEG images or in most digital video files.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Strength</strong><br />
        <em
          >Intensity of the deblocking effect; the higher the strength, the
          higher the number of removed artifacts (but also details).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Reduce artifacts in a snapshot from a CCTV video.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Reduce artifacts in a picture taken with a digital camera.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Reduce artifacts before deblurring, which is very sensitive to them.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        R. Castagno, S. Marsi and G. Ramponi, “A simple algorithm for the
        reduction of blocking artifacts in images and its implementation”, in
        IEEE Transactions on Consumer Electronics, Vol. 44, No. 3, pp.
        1062–1070, August 1998.
        <a href="http://dx.doi.org/10.1109/30.713235" target="_blank"
          >http://dx.doi.org/10.1109/30.713235</a
        >
      </li>
    </ul>
    <hr />
    <h2><a name="Deblurring">Deblurring</a></h2>
    <p><em>Reduces image blurring.</em></p>
    <hr />
    <h3><a name="Motion-Deblurring">Motion Deblurring</a></h3>
    <p>
      <em
        >Corrects the blur caused by linear motion (moving subjects or
        camera).</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Motion Deblurring</em> reduces the blurring effect caused by objects
      moving too fast during the image acquisition process. The algorithm is
      based on a Wiener filtering having, as point spread function (PSF), a line
      <em>Size</em> pixels long with an angle of <em>Angle</em> degrees.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Length of the blur, expressed in pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Angle</strong><br />
        <em
          >Angle of the blur direction, expressed in degrees with respect to the
          horizontal.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Noise</strong><br />
        <em>Estimate of the noise-to-signal power ratio.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em
          >Selects if using a classical linear PSF or two isolated points to
          correct replica issues.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Thickness</strong><br />
        <em
          >Thickness of the blur, expressed in pixels. This allows to consider
          also an optical deblurring component.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Point Spread Function</strong><br />
        <em>The Point Spread Function generated with the current settings.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Boundary Conditions</strong><br />
        <em>Reduce ringing artifacts near the boundaries of the image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Very often it is possible to estimate the values of those parameters by
      looking for the endpoints of a segment of the blurred area that in a
      properly-focused image should converge into a single point. The
      <em>Ruler</em> tool is automatically activated by the Motion Deblurring
      filter, so you can select the endpoints of the blur segment: by doing this
      you will automatically configure the <em>Shift</em> and
      <em>Angle</em> parameters. Some extra fine-tuning may be necessary.<br />
      In order to filter out the noise it is possible to set the
      <em>Noise</em> parameter, which represents the estimated noise-to-signal
      power ratio of the image.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Deblur a license plate of a moving car.<a href="" target="_blank"></a>
      </li>
      <li>
        Deblur a license plate in a wrongly encoded video (replica).<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Deblur a badge from a moving camera.<a href="" target="_blank"></a>
      </li>
      <li>Deblur a moving face.<a href="" target="_blank"></a></li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Jae S. Lim, “Two-Dimensional Signal and Image Processing”, Prentice
        Hall, Englewood Cliffs, NJ, 1990. ISBN: 0-13-935322-4.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 276–284, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Optical-Deblurring">Optical Deblurring</a></h3>
    <p>
      <em>Corrects the blur of objects that are out of focus (big blur).</em>
    </p>
    <h4>Details</h4>
    <p>
      <em>Optical Deblurring</em> reduces the blurring effect due to incorrect
      focus settings during the image acquisition process. The algorithm is
      based on a Wiener filtering, having a circle of diameter <em>Size</em> as
      point spread function (PSF).<br />
      In order to filter out the noise it is possible to set the
      <em>Noise</em> parameter, which represents the estimated noise-to-signal
      power ratio of the image.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>The radius of the point spread function in pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Noise</strong><br />
        <em>Estimate of the noise-to-signal power ratio.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Point Spread Function</strong><br />
        <em>The Point Spread Function generated with the current settings.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Boundary Conditions</strong><br />
        <em>Reduce ringing artifacts near the boundaries of the image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>Deblur an object out of focus.<a href="" target="_blank"></a></li>
      <li>
        Deblur a license plate out of focus.<a href="" target="_blank"></a>
      </li>
      <li>Deblur a face out of focus.<a href="" target="_blank"></a></li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Jae S. Lim, “Two-Dimensional Signal and Image Processing”, Prentice
        Hall, Englewood Cliffs, NJ, 1990. ISBN: 0-13-935322-4.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 276–284, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Nonlinear-Deblurring">Nonlinear Deblurring</a></h3>
    <p><em>Corrects the blur caused by nonlinear motion.</em></p>
    <h4>Details</h4>
    <p>
      <em>Nonlinear Deblurring</em> reduces the blurring effect caused by
      objects moving too fast during the image acquisition process. The
      algorithm is based on a Wiener filtering, having as point spread function
      (PSF) a spline created by user selected points.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Points</strong><br />
        <em>List of the points of the blur, expressed in pixels.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Noise</strong><br />
        <em>Estimate of the noise-to-signal power ratio.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Thickness</strong><br />
        <em
          >Thickness of the blur, expressed in pixels. This allows to consider
          also an optical deblurring component.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Point Spread Function</strong><br />
        <em
          >The Point Spread Function generated by interpolating the points
          selected by the user.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Boundary Conditions</strong><br />
        <em>Reduce ringing artifacts near the boundaries of the image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      In order to determine the shape of PSF you need to add several points over
      a blurred object in the picture, tracking the motion of the object or the
      camera. User submitted points will be connected by a spline curve.<br />
      In order to filter out the noise it is possible to set the
      <em>Noise</em> parameter, which represents the estimated noise-to-signal
      power ratio of the image.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Deblur a license plate with a complex curved blur.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Jae S. Lim, “Two-Dimensional Signal and Image Processing”, Prentice
        Hall, Englewood Cliffs, NJ, 1990. ISBN: 0-13-935322-4.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 276–284, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Blind-Deconvolution">Blind Deconvolution</a></h3>
    <p>
      <em
        >Corrects the blur of objects out of focus with blind deconvolution
        (automatic estimation of little blur).</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Blind Deconvolution</em> reduces the blurring effect caused by wrong
      focus settings during the image acquisition process. The filter is based
      on the blind deconvolution algorithm with a <em>Size</em> x
      <em>Size</em> point spread function (PSF).<br />
      The filter strength is adjusted by the parameter <em>Iterations</em> which
      indicates the number of times the filter is applied.<br />
      In order to reduce the ringing effect, it is possible to set the
      <em>Noise</em> parameter, which represents the estimated noise-to-signal
      power ratio of the image.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Point Spread Function (PSF) size of the blur.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Iterations</strong><br />
        <em>Number of times the filter is applied.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Noise</strong><br />
        <em>Estimate of the noise-to-signal power ratio.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Deblur a license plate from an analog video.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 322–323, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        D. S. C. Biggs and M. Andrews, “Acceleration of iterative image
        restoration algorithms”, in Applied Optics, Vol. 36, No. 8, 1997.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        R. J. Hanisch, R. L. White and R. L. Gilliland, “Deconvolutions of
        Hubble Space Telescope Images and Spectra”, in Deconvolution of Images
        and Spectra, 2nd Ed., P. A. Jansson Ed., Academic Press, CA, 1997.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Timothy J. Holmes, et al, “Light Microscopic Images Reconstructed by
        Maximum Likelihood Deconvolution”, in Handbook of Biological Confocal
        Microscopy, James B. Pawley Ed., Plenum Press, New York, 1995.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Turbulence-Deblurring">Turbulence Deblurring</a></h3>
    <p>
      <em
        >Corrects the blur caused by air turbulence on long distances or by high
        ambient air temperature/humidity.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      Light can follow a slightly curved trajectory if the temperature or
      humidity of the air change along the path. This becomes especially visible
      on images or videos captured from a long distance: objects appear to
      slightly wobble and become blurred. <em>Turbulence Deblurring</em> can
      reduce this specific type of blur. The algorithm is based on a Wiener
      filter, with a point spread function derived from a mathematical model of
      atmospheric turbulence. The <em>Strength</em> parameter is equal to the
      radius in pixels of the point spread function at half maximum.<br />
      In order to filter out the noise it is possible to set the
      <em>Noise</em> parameter, which represents the estimated noise-to-signal
      power ratio of the image.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Strength</strong><br />
        <em>Radius of the point spread function at half maximum.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Noise</strong><br />
        <em>Estimate of the noise-to-signal power ratio.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Point Spread Function</strong><br />
        <em>The Point Spread Function generated with the current settings.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Boundary Conditions</strong><br />
        <em>Reduce ringing artifacts near the boundaries of the image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Deblur a license plate from a long range video with turbulence.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Jae S. Lim, “Two-Dimensional Signal and Image Processing”, Prentice
        Hall, Englewood Cliffs, NJ, 1990. ISBN: 0-13-935322-4.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 276–284, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        R. E. Hufnagel and N. R. Stanley, “Modulation Transfer Function
        Associated with Image Transmission through Turbulent Media”, in Journal
        of the Optical Society of America, Vol. 54, No. 1, pp. 52–61, 1964.
        <a href="http://dx.doi.org/10.1364/JOSA.54.000052" target="_blank"
          >http://dx.doi.org/10.1364/JOSA.54.000052</a
        >
      </li>
    </ul>
    <hr />
    <h2><a name="Stabilization">Stabilization</a></h2>
    <p><em>Stabilizes video frames.</em></p>
    <hr />
    <h3><a name="Local-Stabilization">Local Stabilization</a></h3>
    <p>
      <em
        >Stabilizes a shaking video by keeping the current selection steady. The
        object of interest must be present in all frames. Supports different
        stabilization modes.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Local Stabilization</em> tool horizontally and/or vertically
      shifts the different frames of a video in order to correct instability.
      The offset to be applied is calculated by finding the maximum of the
      cross-correlation function between each frame and a template, which is
      obtained by the reference area copied from the reference frame.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Select with the <em>Selector</em> tool the area of the image that you
      would like to keep steady. When clicking on the <em>Apply</em> button, the
      current frame will be set as reference frame and the currently selected
      area will be set as reference region. Use static template if the image
      does not change very much, dynamic template if the scene changes and the
      static mode is not enough to stabilize the frames. With
      <em>Dynamic</em> template update be careful that the result will be
      different if you will jump from frame to frame rather than playing them
      sequentially.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Stabilize a subject in a shaky video.<a href="" target="_blank"></a>
      </li>
      <li>
        Stabilize a car to keep it in the same part of the video.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Stabilize a person to keep her in the same part of the video.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Stabilize a license plate as preprocessing for frame averaging.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Stabilize a face as preprocessing for frame averaging.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        Static & Dynamic Tracking: never miss your object(ive)!:
        <a
          href="https://blog.ampedsoftware.com/2019/02/01/static-dynamic-tracking-never-miss-your-objective/"
          target="_blank"
          >https://blog.ampedsoftware.com/2019/02/01/static-dynamic-tracking-never-miss-your-objective/</a
        >
      </li>
      <li>
        Image and Video Stabilization with بـستا:
        <a
          href="https://blog.ampedsoftware.com/2013/05/15/image-and-video-stabilization-with-amped-five/"
          target="_blank"
          >https://blog.ampedsoftware.com/2013/05/15/image-and-video-stabilization-with-amped-five/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Global-Stabilization">Global Stabilization</a></h3>
    <p>
      <em
        >Stabilizes the overall scene of a shaking video. Does not need a
        specific object, but also stabilizes a changing scene.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Global Stabilization</em> tool stabilizes a video where the scene
      is subject to camera motion, reducing its temporal high frequencies. For
      each frame in the input video, a symmetric sliding window of
      <em>Frames</em> frames is taken. The relative motion between each pair of
      adjacent frames is calculated with a decimated block matching. Finally,
      the displacement correction for the current frame is computed by means of
      a median filter.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Maximum Shift</strong><br />
        <em
          >The maximum horizontal and vertical shifts (in pixels) to
          correct.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Frames</strong><br />
        <em>The number of frames to be considered for the stabilization.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      This filter is more robust than <em>Local Stabilization</em> with respect
      to zoom and panning, but it is less precise if you are interested in
      finely stabilizing an object of interest.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Stabilize the video of a body worn camera.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Stabilize the video of a fight outside a bar taken with a mobile
        phone.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        L. Tenze, S. Carrato and G. Ramponi, An alignment algorithm for old
        motion pictures, IEEE Signal Processing Letters, vol.9, no.10, Oct.
        2002, pp.309-311.<a href="" target="_blank"></a>
      </li>
      <li>
        Y. Matsushita, E. Ofek, X. Tang, H. Shum, Full-frame video
        stabilization, Proc. Computer Vision and Pattern Recognition, vol.1,
        2005, pp.50-57.<a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        Image and Video Stabilization with بـستا:
        <a
          href="https://blog.ampedsoftware.com/2013/05/15/image-and-video-stabilization-with-amped-five/"
          target="_blank"
          >https://blog.ampedsoftware.com/2013/05/15/image-and-video-stabilization-with-amped-five/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Perspective-Stabilization">Perspective Stabilization</a></h3>
    <p>
      <em
        >Local Stabilization of planar objects, capable of tracking perspective
        transformations.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Perspective Stabilization</em> tool shifts and warps the different
      frames of a video with sub-pixel accuracy, in order to keep a selected
      region as steady as possible even if the object and/or the camera are
      moving.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Quadrilateral region, on the first frame, that you would like to keep
          steady.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Motion Type</strong><br />
        <em
          >Type of motion of the tracked region. A more complex motion can give
          more accurate results but takes more time to compute and is more
          sensitive to noise or motion blur.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Tracking Method</strong><br />
        <em
          ><em>Static Tracking</em> compares the current frame with the first.
          <em>Dynamic Tracking</em> compares the current frame with the
          previous. <em>Hybrid Tracking</em> compares the current frame with
          both the first and the previous (available only for
          <em>Rotation and Zoom</em> and <em>Perspective</em>).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Interpolation</strong><br />
        <em>Interpolation algorithm.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Mode</strong><br />
        <em>Type of output you require.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Homography</strong><br />
        <em>Transformation matrix calculated for the current frame.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Using the <em>Quadrilateral</em> tool select, on the first frame, the
      region that you would like to keep steady. For best results, you should
      select the largest possible planar surface that contains the region of
      interest (e.g. not just a number plate, but the entire front/back of the
      vehicle). If the object of interest is approaching the camera, you may use
      the <em>Reverse</em> filter to place, at the beginning of the video, the
      frame where the object is largest.<br />
      Select the <em>Motion Type</em> that best describes how the region changes
      during the video. <em>Translation</em> is similar to the
      <em>Local Stabilization</em> filter but adds sub-pixel accuracy.
      <em>Rotation</em> is suitable for small rotations (in the computation, the
      sine of the rotation angle is approximated by the angle).
      <em>Rotation and Zoom</em> supports large rotation angles and may be
      suitable, for instance, to stabilize a video of a static object captured
      with a hand-held camera. <em>Perspective</em> is the most general setting,
      and can give the most accurate results for moving objects, but also takes
      more time to compute, is more sensitive to noise and may fail if the
      motion is too fast or if the video is affected by motion blur.<br />
      The <em>Tracking Method</em> determines which frames are compared.
      <em>Static Tracking</em> compares the current frame with the first; this
      offers a good stabilization but may fail if the shape of the region
      changes too much. <em>Dynamic Tracking</em> compares each frame with the
      previous; this setting is able to stabilize larger deformations but the
      position of the region in the stabilized video may drift slightly over
      time. <em>Hybrid Tracking</em> (available only for
      <em>Rotation and Zoom</em> and <em>Perspective</em>) compares the current
      frame with both the first and the previous; this allows to track large
      deformations while keeping the target steady.<br />
      In the <em>Output</em> tab, setting <em>Output Mode</em> to
      <em>Stabilized Video</em> warps each frame, according to the selected
      <em>Motion Type</em>, in order to keep the selection steady.
      <em>Prepare for Perspective Super Resolution</em> leaves the video
      unaltered but attaches the transformation matrix to each frame; you can
      then apply the <em>Perspective Super Resolution</em> filter to enlarge the
      stabilized region. <em>Selection Overlay</em> draws the warped selection
      onto the input video. You can automatically add the
      <em>Perspective Super Resolution</em> filter by clicking on the
      <em>Prepare for Perspective Super Resolution</em> button. You can
      optionally add a filter of the <em>Select Frames</em> group between the
      <em>Perspective Stabilization</em> and
      <em>Perspective Super Resolution</em> filters to discard frames that have
      not been stabilized properly. Please note that adding other filters in
      between may give unexpected results.
    </p>
    <h4>Related Links</h4>
    <ul>
      <li>
        To Us "Nice" is Not Enough: Learn How to Further Improve Your Super
        Resolution Images in بـستا:
        <a
          href="https://blog.ampedsoftware.com/2020/01/21/to-us-nice-is-not-enough-learn-how-to-further-improve-your-super-resolution-images-in-amped-five/"
          target="_blank"
          >https://blog.ampedsoftware.com/2020/01/21/to-us-nice-is-not-enough-learn-how-to-further-improve-your-super-resolution-images-in-amped-five/</a
        >
      </li>
      <li>
        When Simple Things Matter: Learn Why Reversing the Video May Greatly
        Improve Your Results:
        <a
          href="https://blog.ampedsoftware.com/2019/05/07/when-simple-things-matter-learn-why-reversing-the-video-may-greatly-improve-your-results/"
          target="_blank"
          >https://blog.ampedsoftware.com/2019/05/07/when-simple-things-matter-learn-why-reversing-the-video-may-greatly-improve-your-results/</a
        >
      </li>
      <li>
        Perspective Stabilization and Perspective Super Resolution:
        <a
          href="https://blog.ampedsoftware.com/2018/11/08/perspective-stabilization-and-perspective-super-resolution/"
          target="_blank"
          >https://blog.ampedsoftware.com/2018/11/08/perspective-stabilization-and-perspective-super-resolution/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Perspective-Registration">Perspective Registration</a></h3>
    <p>
      <em
        >Aligns the perspective of different images of the same object, taken
        from different points of view. Supports any kind of motion (shift,
        rotation, zoom, perspective changes).</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Perspective Registration</em> aligns an object of interest in all
      frames with respect to a reference frame by a projective geometric
      transformation. For each frame, except for the reference one, the
      homography matrix which maps four control points of the frame to the
      corresponding points of the reference frame is calculated. The result can
      be refined by an optimization process which maximizes, through the
      Nelder-Mead simplex method, the correlation between the region of interest
      on the reference frame and each transformed frame.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Selections</strong><br />
        <em
          >Vector containing, for each frame, the points chosen for
          selection.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Reference Frame</strong><br />
        <em>Position of the reference frame.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Original Homography</strong><br />
        <em>Transformation matrix calculated by selected points.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Optimized Homography</strong><br />
        <em
          >Transformation matrix calculated optimizing the original
          homography.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Optimization</strong><br />
        <em
          >If enabled, the area selected on each image is automatically
          optimized so that the filter can give the best results.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 320–322, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        Image and Video Stabilization with بـستا:
        <a
          href="https://blog.ampedsoftware.com/2013/05/15/image-and-video-stabilization-with-amped-five/"
          target="_blank"
          >https://blog.ampedsoftware.com/2013/05/15/image-and-video-stabilization-with-amped-five/</a
        >
      </li>
    </ul>
    <hr />
    <h2><a name="Integrate">Integrate</a></h2>
    <p><em>Enhances image by multiple frames.</em></p>
    <hr />
    <h3><a name="Temporal-Smoothing">Temporal Smoothing</a></h3>
    <p>
      <em
        >Reduces the noise integrating multiple frames. Gives the same number of
        frames in output as in input.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Temporal Smoothing</em> tool reduces the noise in the image by
      creating an output frame that is the pixel-by-pixel average of the current
      frame with the previous ones. The number of the frames taken into account
      is given by the parameter <em>Size</em>.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em
          >Size (in frames) of the "temporal window" to be used, i.e. the number
          of frames to average.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Note that if there are moving objects on the scene, they will result
      blurred by the filter. In this case, it is recommended to use the
      <em>Motion Smoothing</em>. The effect is generally softer than that one
      obtained with the <em>Temporal Smoothing</em>. Moreover, it will keep
      sharp even moving objects.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>Reduce the noise in a dark video.<a href="" target="_blank"></a></li>
    </ul>
    <hr />
    <h3><a name="Motion-Smoothing">Motion Smoothing</a></h3>
    <p>
      <em
        >Reduces the noise integrating current and previous frames and avoiding
        halos on moving objects.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Motion Smoothing</em> tool reduces the noise in a video by
      processing each image along with the previous and the next frame. Each
      pixel of the output image is calculated from the neighboring pixels in the
      same frame and from the values of the pixel in the same position in the
      previous and next frames. Since the moving objects are recognized by the
      filter, they won't be blurred as it happens with simpler temporal filters,
      such as the temporal smoothing.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Still Smooth</strong><br />
        <em>Smoothing strength from the current frame.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Still Details</strong><br />
        <em>Details preservation from the current frame.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Motion Smooth</strong><br />
        <em>Smoothing contribution from the neighboring frames.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Motion Details</strong><br />
        <em>Details contribution from the neighboring frames.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>Reduce the noise in a dark video.<a href="" target="_blank"></a></li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        G. Ramponi, S. Marsi and S. Carrato, “Image processing using rational
        functions”, in Nonlinear Model-Based Image/Video Processing and
        Analysis, C. Kotropoulos and Ioannis Pitas, Eds., John Wiley & Sons,
        2001. ISBN: 0-471-37735-X.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Frame-Averaging">Frame Averaging</a></h3>
    <p>
      <em
        >Reduces the noise by creating an image which is the average of all the
        frames. Gives an output of a single image.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Frame Averaging</em> calculates and implements a pixel-by-pixel mean
      along all the frames of the video.
    </p>
    <h4>Parameters</h4>
    <em>This filter has no parameters.</em>
    <h4>Usage</h4>
    <p>
      Please note that, while this filter needs multiple frames as input, it
      outputs one single frame.<br />
      This filter, when applied to a single image, outputs a copy of the source.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>Improve a dark scene.<a href="" target="_blank"></a></li>
      <li>
        Improve the readability of a license plate.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>Improve the quality of a face.<a href="" target="_blank"></a></li>
    </ul>
    <hr />
    <h3><a name="Super-Resolution">Super Resolution</a></h3>
    <p>
      <em
        >Generates a single higher-resolution image by merging all the frames
        with subpixel motion estimation.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Super Resolution</em> filter applies a sub-pixel registration to
      all the frames of a video, then merges the motion corrected frames
      together, along with a deblurring filtering. If a <em>Selection</em> is
      set, then the selected area will be optimized.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Zoom</strong><br />
        <em>Zoom factor for the output image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Iterations</strong><br />
        <em>Number of deblurring steps.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em>Region of the image to optimize.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Improve the readability of a license plate.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>Improve the quality of a face.<a href="" target="_blank"></a></li>
      <li>Improve the readability of text.<a href="" target="_blank"></a></li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Hiroyuki Takeda, Peyman Milanfar, Matan Protter and Michael Elad,
        “Super-resolution without explicit subpixel motion estimation”, in IEEE
        Transactions on Image Processing, Vol. 18, No. 9, pp. 1958–1975,
        September 2009.
        <a href="http://dx.doi.org/10.1109/TIP.2009.2023703" target="_blank"
          >http://dx.doi.org/10.1109/TIP.2009.2023703</a
        >
      </li>
    </ul>
    <hr />
    <h3>
      <a name="Perspective-Super-Resolution">Perspective Super Resolution</a>
    </h3>
    <p>
      <em
        >Generates a single higher-resolution image by merging all the frames of
        a video stabilized with the [Perspective Stabilization] filter.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Perspective Super Resolution</em> filter takes the output of
      <em>Perspective Stabilization</em> and uses it to compute a super
      resolution of the input video.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Zoom</strong><br />
        <em>Enlargement factor.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Output Size</strong><br />
        <em>Size of the output frame.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Sharpening</strong><br />
        <em>The sharpening effect of the filter.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Apply the <em>Perspective Stabilization</em> tool checking the
      <em>Prepare for Perspective Super Resolution</em> output option. Then,
      apply the <em>Perspective Super Resolution</em> tool after it. It is
      optionally possible to insert a filter of the <em>Select Frames</em> group
      in between, to discard the frames where the stabilization has failed. The
      image is automatically enlarged around the center of the quadrilateral
      defined in <em>Perspective Stabilization</em>. The
      <em>Sharpening</em> slider adjusts the sharpness of the processed image; a
      higher value increases the sharpness but may produce a grainy output,
      especially if the number of frames of the input video is low.
    </p>
    <h4>Related Links</h4>
    <ul>
      <li>
        To Us "Nice" is Not Enough: Learn How to Further Improve Your Super
        Resolution Images in بـستا:
        <a
          href="https://blog.ampedsoftware.com/2020/01/21/to-us-nice-is-not-enough-learn-how-to-further-improve-your-super-resolution-images-in-amped-five/"
          target="_blank"
          >https://blog.ampedsoftware.com/2020/01/21/to-us-nice-is-not-enough-learn-how-to-further-improve-your-super-resolution-images-in-amped-five/</a
        >
      </li>
      <li>
        When Simple Things Matter: Learn Why Reversing the Video May Greatly
        Improve Your Results:
        <a
          href="https://blog.ampedsoftware.com/2019/05/07/when-simple-things-matter-learn-why-reversing-the-video-may-greatly-improve-your-results/"
          target="_blank"
          >https://blog.ampedsoftware.com/2019/05/07/when-simple-things-matter-learn-why-reversing-the-video-may-greatly-improve-your-results/</a
        >
      </li>
      <li>
        Perspective Stabilization and Perspective Super Resolution:
        <a
          href="https://blog.ampedsoftware.com/2018/11/08/perspective-stabilization-and-perspective-super-resolution/"
          target="_blank"
          >https://blog.ampedsoftware.com/2018/11/08/perspective-stabilization-and-perspective-super-resolution/</a
        >
      </li>
    </ul>
    <hr />
    <h2><a name="Presentation">Presentation</a></h2>
    <p><em>Prepares a video or image for presentation.</em></p>
    <hr />
    <h3><a name="Compare-Original">Compare Original</a></h3>
    <p>
      <em
        >Juxtaposes or overlays original and enhanced images for comparison.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Compare Original</em> tool allow to display side by side the
      original images with the processed ones in order to easily understand how
      the processing has enhanced the image.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em
          >How to display the processed and the original (or unprocessed)
          images, videos or frames.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Balance</strong><br />
        <em>Balance between the original (0) and processed image (1).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Gain</strong><br />
        <em>Gain applied to the output image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Line Color</strong><br />
        <em
          >The color of the separating line in Half Horizontally and Half
          Vertically mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Line Thickness</strong><br />
        <em
          >The thickness of the separating line in Half Horizontally and Half
          Vertically mode.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Compare a license plate before and after the enhancement.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Compare a face before and after the enhancement.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Compare a video before and after the stabilization.<a
          href=""
          target="_blank"
        ></a>
      </li>
      <li>
        Compare a video keeping the stabilization on an object (putting a Video
        Writer before).<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Spotlight">Spotlight</a></h3>
    <p>
      <em
        >Adds a spotlight effect to a selection. Supports different tracking
        methods and inverse selection.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Spotlight</em> modifies contrast and brightness of a selection of the
      image to highlight it in the scene.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Contrast</strong><br />
        <em>Extends the intensity difference among pixel (linear gain).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Brightness</strong><br />
        <em>Adds or subtracts an offset to image pixels (bias).</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Shape</strong><br />
        <em>Defines the shape of the selection.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection Type</strong><br />
        <em>Defines if the selection is normal or inverted.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>Highlight the car of interest.<a href="" target="_blank"></a></li>
      <li>Highlight the person of interest.<a href="" target="_blank"></a></li>
    </ul>
    <h4>References</h4>
    <ul>
      <li>
        Anil. K. Jain, “Fundamentals of Digital Image Processing”, Prentice
        Hall, pp. 234–241, 1989. ISBN: 0-13-336165-9.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Hide-Selection">Hide Selection</a></h3>
    <p>
      <em
        >Pixelates, darkens or blurs a selected area in a video (redaction for
        privacy, witness protection, or sensitive subjects). Supports different
        tracking methods and inverse selection.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Hide Selection</em> tool hides the selected area using three
      different methods:<br />
      - <em>Smooth</em>: the selected area is processed by a smoothing
      algorithm;<br />
      - <em>Pixelate</em>: the selected area is pixelated;<br />
      - <em>Black</em>: the selected area is turned blackened.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Mode</strong><br />
        <em>Type of method to use.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Size</strong><br />
        <em>Adjusts the size of the blur or pixelation.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Shape</strong><br />
        <em>Defines the shape of the selection.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection Type</strong><br />
        <em>Defines if the selection is normal or inverted.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Redact a face from a body worn video.<a href="" target="_blank"></a>
      </li>
      <li>
        Blur everything but a specific subject.<a href="" target="_blank"></a>
      </li>
      <li>Pixelate a license plate.<a href="" target="_blank"></a></li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        Video Redaction with بـستا:
        <a
          href="https://blog.ampedsoftware.com/2018/05/24/video-redaction-with-amped-five/"
          target="_blank"
          >https://blog.ampedsoftware.com/2018/05/24/video-redaction-with-amped-five/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Load-Timestamp">Load Timestamp</a></h3>
    <p>
      <em
        >Displays subtitles on the video frame. Font, color, size and position
        can be customized.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      This filter loads subtitles from a srt or smi file format and displays
      them in the proper frames.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>File</strong><br />
        <em>Path of the subtitle file to load.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Text Style</strong><br />
        <em>Specify text font, size and color.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Disable rendering</strong><br />
        <em
          >Don't draw the timestamp, just propagate the timestamp information
          down the filters chain to the Add Text filter.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Timestamp format</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em>Position of the timestamp.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>Load timestamp from a CCTV video.<a href="" target="_blank"></a></li>
      <li>
        Add timestamp on a border (Frame Size).<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Add-Timestamp">Add Timestamp</a></h3>
    <p>
      <em
        >Indicates date and time for the current frame. Font, color, size and
        position can be customized.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Write Timestamp</em> filter allows to provide time indication for
      videos lacking a time stamp. Given the two known dates and times
      corresponding to two reference frames, it will calculate for every frame
      an approximate timestamp with a linear approximation. For videos which do
      not have a constant frame rate the timestamp may not be accurate.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>First frame</strong><br />
        <em>First reference frame.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>First timestamp</strong><br />
        <em>Date and time of the first reference frame.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Second frame</strong><br />
        <em>Second reference frame.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Second timestamp</strong><br />
        <em>Date and time of the second reference frame.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Disable rendering</strong><br />
        <em
          >Don't draw the timestamp, just propagate the timestamp information
          down the filters chain to the Add Text filter.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Adjust Frame Rate</strong><br />
        <em>Frame rate adjustment settings.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Text Style</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Time Format</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Standard Formats</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em>Position of the timestamp.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      You can customize the date and time format as follows:<br />
      %a: Abbreviated weekday name<br />
      %A: Full weekday name<br />
      %b: Abbreviated month name<br />
      %B: Full month name<br />
      %c: Date and time representation appropriate for locale<br />
      %d: Day of month as decimal number (01 - 31)<br />
      %H: Hour in 24-hour format (00 - 23)<br />
      %I: Hour in 12-hour format (01 - 12)<br />
      %j: Day of year as decimal number (001 - 366)<br />
      %l: Milliseconds with leading zeros (000 - 999)<br />
      %m: Month as decimal number (01 - 12)<br />
      %M: Minute as decimal number (00 - 59)<br />
      %p: Current locale's A.M./P.M. indicator for 12-hour clock<br />
      %S: Second as decimal number (00 - 59)<br />
      %U: Week of year as decimal number, with Sunday as first day of week (00 -
      53)<br />
      %w: Weekday as decimal number (0 - 6; Sunday is 0)<br />
      %W: Week of year as decimal number, with Monday as first day of week (00 -
      53)<br />
      %x: Date representation for current locale<br />
      %X: Time representation for current locale<br />
      %y: Year without century, as decimal number (00 - 99)<br />
      %Y: Year with century, as decimal number<br />
      %z, %Z: Either the time zone name or time zone abbreviation, depending on
      registry settings; no characters if time zone is unknown<br />
      %%: Percent sign<br />
      %#a, %#A, %#b, %#B, %#p, %#X, %#z, %#Z, %#%: # flag is ignored<br />
      %#c: Long date and time representation, appropriate for current locale.
      For example: "Tuesday, March 14, 1995, 12:41:29".<br />
      %#x: Long date representation, appropriate to current locale. For example:
      "Tuesday, March 14, 1995"<br />
      %#d, %#H, %#I, %#j, %#m, %#M, %#S, %#U, %#w, %#W, %#y, %#Y: Remove leading
      zeros (if any).<br />
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Add the time on a video with known times.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Annotate">Annotate</a></h3>
    <p><em>Draws annotations over the image.</em></p>
    <h4>Details</h4>
    <p>
      <em>Annotate</em> enables drawing annotations over the image: shapes,
      arrows, lines. Also, allows for adding texts, images, hiding an area,
      magnifying an area.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Annotation Tool</strong><br />
        <em>A set of modes with their respective parameters.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Select a mode from settings panel, then draw or edit objects.<br />
      <br />
      - Shape - Draw on images and frames using various shapes (rectangle,
      circle). Simply drag a shape on the frame or image using the mouse to
      produce the annotation. Size, transparency and colors can be selected
      according to preference.<br />
      - Arrow - Draw on images and frames using arrows or lines. Simply drag an
      arrow on the frame or image using the mouse to produce the annotation.
      Size and color can be selected according to preference.<br />
      - Pencil - Freehand drawing on images and frames. Simply draw on the frame
      or image using the mouse. Size and color can be selected according to
      preference.<br />
      - Add Text - The Font and size can be selected, along with the style
      (bold, italic or underlined). It is possible to select the color of the
      text and add a background color or keep it as transparent using the
      checkbox next to the color choice. The Horizontal Alignment can be chosen
      between Center, Left or Right as can the Vertical Alignment.<br />
      - Add an Image or Logo - Simply click the three white dots and the
      software will open a browser window for navigating to the logo or image to
      be used. There is the option to maintain or ignore the aspect ratio and to
      treat white or black colors in the image as transparent.<br />
      - Hide (Blur or Pixelate) - Here the strength of the redaction can be
      chosen as well as the shape and any border color. The border thickness can
      also be adjusted.<br />
      - Magnify a Specific Area - Simply drag the selection tool over the area
      to be magnified. The blue circle in the middle of the selection allows for
      magnifying an object or subject but then showing the results in a
      different area on the image. In this case, keep the blue circle on the
      object or subject you want to magnify and move the selection box to the
      area you want. There is the choice of zoom level, shape, border color and
      thickness and the type of border.<br />
      - Spotlight - Highlight an image region by modifying its contrast and
      brightness. Drag the selection tool over the area to 'put the light' on
      it. Shape and border can be adjusted according to preference.<br />
      <br />
      You can clear annotations by clicking the General button and selecting
      Clear All.<br />
      <br />
      After drawing an annotation, clicking the right mouse button whilst
      hovering over the annotation will give you the following options:<br />
      - Lock - This will toggle on / off shape locking, to prevent accidental
      editing or deletion after that the shape has been completed.<br />
      - Copy - This will copy the selected annotation so it can be used
      again.<br />
      - Paste - This will paste any annotation that has previously been
      copied.<br />
      - Delete - This will delete the selected annotation.<br />
      - Bring To Front - If you are using multiple annotations in layers, this
      will bring the selected layer to the very front of the annotation
      group.<br />
      - Bring Forward - If you are using multiple annotations in layers, this
      will bring the selected layer forward by one place within the annotation
      group.<br />
      - Send Backward - If you are using multiple annotations in layers, this
      will send the selected layer backwards by one place within the annotation
      group.<br />
      - Send To Back - If you are using multiple annotations in layers, this
      will send the selected layer to the very back of the annotations group.<br />
      - Set Only For This Frame - This will set the selected annotation to show
      only on the current frame when annotating video or image sequences.<br />
      - Set From This Frame - This will set the selected annotation to show from
      the current frame and allow for navigation to another frame, meaning the
      annotation will show only in the range between those two frame points.<br />
      - Set Until This Frame - This will set the selected annotation from a
      previously selected frame of the video until the current frame of a video
      or image sequence.<br />
      - Set For All Frames - This will set the selected annotation to appear for
      the entire video or image sequence.<br />
      - Go To First Frame (N) - This will navigate to the first frame the
      annotation appears on. The number in brackets is the frame number.<br />
      - Go To Last Frame (N) - This will navigate to the last frame the
      annotation appears on. The number in brackets is the frame number.<br />
      <br />
      Annotations can be applied independently to frames or to the entire video.
      An annotation can be moved along a freehand path to keep highlight over a
      subject. Recording the freehand path can be performed as follow:<br />
      - Open a video containing the subject you wish to track (for example,
      surrounding him/her with a circular shape).<br />
      - Go to first frame of the video where the subject appears.<br />
      - Use the Annotate filter, select an annotation type (any will work, but
      Shape and Hide are the most common choices), then add the annotation over
      the subject.<br />
      - Leave the annotation selected: its control points must be visible and
      coloured in white.<br />
      - Using the Speed slider at the bottom, set the frame rate to a very low
      value like 2 or 4 FPS.<br />
      - Click the Play button. While video is playing at such low speed, slowly
      drag the annotation and keep it centered on the subject.<br />
      - Click the Pause button.<br />
      - Deselect the annotation with one click outside its bounds; the control
      points will disappear.<br />
      <br />
      After recording is completed, we can restore the frame rate to the
      original speed (click on the Reset button), seek back to the frame where
      the subject appeared, and click Play:<br />
      the annotation will move along the path that you just recorded,
      highlighting the desired subject. This shape will be visible also in
      exported videos (Video Writer filter).<br />
      <br />
      A moving subject can be tracked by an automation-assisted procedure when
      the subject appearance changes slowly across frames. Smart tracking can be
      applied as follows:<br />
      - Open a video containing the subject you wish to track (for example,
      surrounding him/her with a circular shape).<br />
      - Go to first frame of the video where the subject appears.<br />
      - Use the Annotate filter, select an annotation type (any will work, but
      Shape and Hide are the most common choices), then add the annotation over
      the subject.<br />
      - Leave the annotation selected: its control points must be visible and
      coloured in white.<br />
      - Now click the Track button once to activate tracking; two rectangles
      will appear:<br />
      - a reference region (green rectangle with dashed lines) to mark precisely
      the subject to be tracked,<br />
      - and a search window (yellow rectangle with dashed lines) which delimits
      the area where the reference could appear in the next frame; a smaller
      search window requires less computations and decreases the chance of
      tracking errors on slow-speed subjects.<br />
      While tracking is active a link-shaped icon appears on entities that
      participate into a joint move/resize action with the current selection:<br />
      - if an annotation is selected, the link icon will appear both on the
      reference region (green) and the search window (yellow)<br />
      - if the reference region (green) is selected, the link icon will appear
      on the search window (yellow)<br />
      - Click again Track: video will advance by one frame, and subject will be
      tracked automatically; hold down Track to apply tracking repeatedly on
      next frames, until button is released.<br />
      - Click Copy button to copy current annotation shape and coordinates
      verbatim into the next frame, without tracking applied; hold down Copy for
      repeated copies in the next frames.<br />
      - Click or hold Next and Previous buttons to navigate along the video, the
      same way as Next Frame and Previous Frame buttons of the player panel
      do.<br />
      The difference between Copy and Next buttons is somewhat subtle, and can
      be observed more clearly when annotation coordinates (position, rotation,
      scale) differ between current and next frame:<br />
      - Copy will overwrite coordinates in next frame, and step forward by one
      frame;<br />
      - Next will just step to next frame, leaving original coordinates
      unchanged.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>Draw annotations over the image.<a href="" target="_blank"></a></li>
    </ul>
    <hr />
    <h3><a name="Add-Logo">Add Logo</a></h3>
    <p>
      <em
        >Superimposes an external image onto the current image or video to mark
        it. Supports transparency (alpha) channel or color to transparency
        conversion.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      <em>Add Logo</em> superimposes an external image onto the current image or
      video. The user can adjust the position of the image with respect to the
      frame or a selection, if present. The image can be made transparent if it
      contains an alpha channel; otherwise, the black or white pixels can be
      made transparent on request.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>File Name</strong><br />
        <em
          >Path of the external image file to superimpose onto the current image
          or video.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Alpha Channel</strong><br />
        <em
          >Informs the user if the selected image file contains transparency
          information.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Horizontal Position</strong><br />
        <em
          >Horizontal position of the superimposed image with respect to the
          frame or selection.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Vertical Position</strong><br />
        <em
          >Vertical position of the superimposed image with respect to the frame
          or selection.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Transparency</strong><br />
        <em
          >Method used to optionally blend the superimposed image with the
          background.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Additional Transparency</strong><br />
        <em>Optionally increase the transparency of the superimposed image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Logo Size</strong><br />
        <em>Logo Size.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Interpolation</strong><br />
        <em>Interpolation algorithm.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Select an image file to use as a superimposed logo and then click
      <em>Apply</em>. Use the <em>Horizontal Position</em> and
      <em>Vertical Position</em> menus to adjust the position of the logo
      relative to the main image frame or, if present, to the current selection.
      If the image contains an alpha channel, it is used automatically to blend
      the logo with the background; it may be necessary to specify if the alpha
      channel is <em>Straight</em> or <em>Premultiplied</em> in the
      <em>Transparency</em> menu. It is also possible to set <em>Black</em> or
      <em>White</em> pixels to transparent, or to disable transparency
      altogether.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Add agency logo on a suspect photo for release.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Add-Text">Add Text</a></h3>
    <p>
      <em
        >Inserts text on the image. Supports several macros to dynamically
        change the content of the text. Font, color, size and position can be
        customized.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Add Text</em> filter allows to put textual information on the
      image.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Text</strong><br />
        <em>The text to write on the image.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Add Macro</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Text Style</strong><br />
        <em>Font characteristics used for the text.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Background Color</strong><br />
        <em
          >The color used to optionally paint the rectangle behind the text.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Background Shape</strong><br />
        <em>The shape of the colored background, if requested.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Date format</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Time format</strong><br />
        <em></em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Add file and frame info on a CCTV video.<a href="" target="_blank"></a>
      </li>
      <li>Annotate people on a video.<a href="" target="_blank"></a></li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        The Flexibility of the Add Text Filter:
        <a
          href="https://blog.ampedsoftware.com/2017/06/13/the-flexibility-of-the-add-text-filter/"
          target="_blank"
          >https://blog.ampedsoftware.com/2017/06/13/the-flexibility-of-the-add-text-filter/</a
        >
      </li>
      <li>
        Brilliant Details: Learn How to Use بـستا’s Macros to Add Adaptive Text
        to Your Frames and Make Compelling Videos:
        <a
          href="https://blog.ampedsoftware.com/2020/02/25/brilliant-details-learn-how-to-use-amped-fives-macros-to-add-adaptive-text-to-your-frames-and-make-compelling-videos/"
          target="_blank"
          >https://blog.ampedsoftware.com/2020/02/25/brilliant-details-learn-how-to-use-amped-fives-macros-to-add-adaptive-text-to-your-frames-and-make-compelling-videos/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Add-Shape">Add Shape</a></h3>
    <p>
      <em>Draws shapes (arrows, lines, rectangles, ellipses) on the image.</em>
    </p>
    <h4>Details</h4>
    <p>
      <em>Add Shape</em> draws rectangle, ellipses, lines and arrows to annotate
      the image.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Shape Type</strong><br />
        <em>The type of shape to draw.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Border Thickness</strong><br />
        <em>The thickness of the shape border.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Line Type</strong><br />
        <em>The type of line used to draw the border of the shape.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Border Color</strong><br />
        <em>Color of the border.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Fill Color</strong><br />
        <em>Color of the area inside the shape.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Fill Area</strong><br />
        <em
          >If enabled, fills the area using the <em>Fill Color</em>; otherwise,
          leaves the shape transparent.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Line Angle</strong><br />
        <em>Rotation angle of the line.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Selection</strong><br />
        <em
          >Selection where the filter is applied. It may be the whole image, a
          static region, or a region containing a tracked object of
          interest.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Follow people with arrows on a video.<a href="" target="_blank"></a>
      </li>
      <li>Circle cars in a video.<a href="" target="_blank"></a></li>
    </ul>
    <hr />
    <h3><a name="Add-Grid">Add Grid</a></h3>
    <p>
      <em
        >Superimposes a grid onto the image or video. Useful for compression
        estimation and other analysis.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Add Grid</em> filter superimposes a regular grid onto the image or
      video. The user can adjust the <em>Size</em>, <em>Offset</em>,
      <em>Thickness</em>, <em>Color</em> and <em>Opacity</em>.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Size X</strong><br />
        <em
          >Distance in pixels between the vertical lines of the grid. Setting
          this value to zero disables the vertical lines.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Size Y</strong><br />
        <em
          >Distance in pixels between the horizontal lines of the grid. Setting
          this value to zero disables the horizontal lines.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Offset X</strong><br />
        <em
          >Distance in pixels between the first vertical line and the left
          border of the image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Offset Y</strong><br />
        <em
          >Distance in pixels between the first horizontal line and the top
          border of the image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Lock X/Y</strong><br />
        <em
          >When enabled, keeps the X values equal to the corresponding Y
          value.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Thickness</strong><br />
        <em>Thickness of the grid in pixels.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Color</strong><br />
        <em>Color of the grid.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Opacity</strong><br />
        <em
          >Opacity of the grid. A value of 1 produces a fully opaque grid;
          smaller values produce a transparent grid that blends with the
          background image.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      The X and Y sizes and offsets of the grid can be adjusted independently,
      or can be kept equal if the <em>Lock X/Y</em> option is set. Each set of
      lines (horizontal or vertical) appears on the screen if the corresponding
      size is greater than the zero.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>Estimate the proper aspect ratio.<a href="" target="_blank"></a></li>
      <li>Analyze macroblocks size.<a href="" target="_blank"></a></li>
      <li>
        Overlay a grid on an image for face comparisons.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Change-Frame-Rate">Change Frame Rate</a></h3>
    <p><em>Changes the frame rate of the video.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Change Frame Rate</em> tool changes the update frequency of a
      video during playback.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Frame Rate</strong><br />
        <em>Frame rate of the output video.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Total Time</strong><br />
        <em>Total time of the output video.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Application Examples</h4>
    <ul>
      <li>Visualize a video in slow motion.<a href="" target="_blank"></a></li>
      <li>
        Restore the proper frame rate after a DVR conversion.<a
          href=""
          target="_blank"
        ></a>
      </li>
    </ul>
    <h4>Related Links</h4>
    <ul>
      <li>
        Changing a Video’s Frame Rate:
        <a
          href="https://blog.ampedsoftware.com/2017/06/06/changing-a-videos-frame-rate/"
          target="_blank"
          >https://blog.ampedsoftware.com/2017/06/06/changing-a-videos-frame-rate/</a
        >
      </li>
    </ul>
    <hr />
    <h3><a name="Convert-Frame-Rate">Convert Frame Rate</a></h3>
    <p>
      <em
        >Adapts the frame rate of a video by duplicating or dropping frames.</em
      >
    </p>
    <h4>Details</h4>
    <p>
      The <em>Convert Frame Rate</em> filter adapts the update frequency of a
      video during playback by duplicating or dropping frames. The playback
      speed remains unchanged. The processing uses a "sample and hold" technique
      that does not alter the content of the input frames. Time-based and
      timestamp-based videos are converted to frame-based videos with a constant
      frame rate.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Frame Rate</strong><br />
        <em>Frame rate of the output video.</em><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Use the <em>Convert Frame Rate</em> filter if you want to change the frame
      rate of a video without changing the playback speed or if you want to
      convert a time- or timestamp-based video to frame-based. Use
      <em>Change Frame Rate</em> if instead you want to change the playback
      speed of a frame-based video.
    </p>
    <h4>Application Examples</h4>
    <ul>
      <li>
        Synchronize the frame rates of different videos before mixing them with
        a filter in the [Link] category.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Reverse">Reverse</a></h3>
    <p><em>Plays back the video in the reverse direction.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Reverse</em> filter is useful when stabilizing videos in which the
      subject is moving towards the camera, and therefore is best visible on the
      last frame.
    </p>
    <h4>Parameters</h4>
    <em>This filter has no parameters.</em>
    <h4>Application Examples</h4>
    <ul>
      <li>
        View an action in the opposite direction.<a href="" target="_blank"></a>
      </li>
      <li>
        Invert the frame sequence for better integration of an object which is
        increasing in size.<a href="" target="_blank"></a>
      </li>
    </ul>
    <hr />
    <h3><a name="Audio-Redaction">Audio Redaction</a></h3>
    <p><em>Redacts parts of the video's audio track.</em></p>
    <h4>Details</h4>
    <p>
      The <em>Audio Redaction</em> tool will replace one or more sections of the
      audio track with silence or some signal (e.g. sinusoid), optionally adding
      fade-in and fade-out effects.
    </p>
    <h4>Parameters</h4>
    <ul>
      <li>
        <strong>Redacted intervals</strong><br />
        <em>List of time intervals where redaction will be applied.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Redaction Type</strong><br />
        <em>The type of signal used to replace the original audio with.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Redaction Volume (dB)</strong><br />
        <em>Volume of the replacement signal.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <ul>
      <li>
        <strong>Fade length (ms)</strong><br />
        <em
          >The length in milliseconds of the fade transition, to smoothly switch
          from original to redacted audio and vice versa.</em
        ><a href="" target="_blank"></a>
      </li>
    </ul>
    <h4>Usage</h4>
    <p>
      Hold ALT and drag mouse over the Audio panel (enable from View menu if
      hidden) to perform redaction.<br />
      - Dragging started over an empty area creates a new redaction region.<br />
      - Dragging a region's border modifies its beginnig or end.<br />
      - Dragging a region's inner area moves it.<br />
      Regions that overlap when finished dragging will be merged.
    </p>
  </body>
</html>
